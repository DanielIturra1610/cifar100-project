{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4krib9eF6idH"
   },
   "source": [
    "# Fase 1 - Comprensión del negocio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pCi6s6m58JSA"
   },
   "source": [
    "En esta fase se identificarán los factores clave necesarios para abordar los objetivos empresariales y se plantearán en objetivos específicos de minería de datos, asegurando que el análisis posterior responda adecuadamente a las necesidades del negocio."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "P-ZYEENd6ZKl"
   },
   "source": [
    "# Fase 2 - Comprensión de los datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2VuADvnE9zGD"
   },
   "source": [
    "Durante esta fase, se realizará una recolección y análisis preliminar de los datos disponibles, con el objetivo de comprender su naturaleza y calidad. Se identificarán patrones iniciales y posibles problemas que puedan afectar el análisis, lo que permitirá guiar el proceso de preparación de los datos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZmRb_ChEjI6H"
   },
   "source": [
    "## Importaciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "eYQNjTv6jLe-"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-28 17:07:47.087081: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-06-28 17:07:47.136439: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2025-06-28 17:07:47.136479: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2025-06-28 17:07:47.137906: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-06-28 17:07:47.145991: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-06-28 17:07:47.147037: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-06-28 17:07:48.141828: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU disponible:  []\n",
      "WARNING:tensorflow:Mixed precision compatibility check (mixed_float16): WARNING\n",
      "The dtype policy mixed_float16 may run slowly because this machine does not have a GPU. Only Nvidia GPUs with compute capability of at least 7.0 run quickly with mixed_float16.\n",
      "If you will use compatible GPU(s) not attached to this host, e.g. by running a multi-worker model, you can ignore this warning. This message will only be logged once\n",
      "Mixed precision activada:  mixed_float16\n",
      "Compilación XLA activada\n"
     ]
    }
   ],
   "source": [
    "# Verificación y configuración de GPU\n",
    "print(\"GPU disponible: \", tf.config.list_physical_devices('GPU'))\n",
    "\n",
    "# Habilitamos mixed precision para acelerar el entrenamiento en GPU\n",
    "try:\n",
    "    policy = tf.keras.mixed_precision.Policy('mixed_float16')\n",
    "    tf.keras.mixed_precision.set_global_policy(policy)\n",
    "    print('Mixed precision activada: ', policy.name)\n",
    "except:\n",
    "    print('Mixed precision no soportada en este entorno')\n",
    "\n",
    "# Activar compilación XLA para acelerar el entrenamiento\n",
    "tf.config.optimizer.set_jit(True)\n",
    "print('Compilación XLA activada')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "s2T3g7peldFB"
   },
   "source": [
    "## Descarga y lectura del texto"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-3IDAE2amD5t"
   },
   "source": [
    "Se descarga el texto, se abre el archivo como binario, se lee y se decodifica en formato UTF-8, este es transformado en minúsculas.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "wILza5-lleNI"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://www.gutenberg.org/files/2000/2000-0.txt\n",
      "2226045/2226045 [==============================] - 1s 0us/step\n"
     ]
    }
   ],
   "source": [
    "path = tf.keras.utils.get_file('quijote.txt', 'https://www.gutenberg.org/files/2000/2000-0.txt')\n",
    "text = open(path, 'rb').read().decode(encoding='utf-8').lower()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "V3AhNYudm5zD"
   },
   "source": [
    "## Extracción de vocabulario único"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oWNpDLLtm-it"
   },
   "source": [
    "Se crea un conjunto con los caracteres distintos, estos se ordenan alfabéticamente y se muestra la cantidad de caracteres únicos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "-7-q_56gm7lU"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "74 caracteres únicos\n"
     ]
    }
   ],
   "source": [
    "vocab = sorted(set(text))\n",
    "print(f'{len(vocab)} caracteres únicos')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oHpVyLtDsJX9"
   },
   "source": [
    "*Pasar a Codificación del texto a numéricos [Fase 3]*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TI-1kM0b7H6Y"
   },
   "source": [
    "# Fase 3 - Preparación de los datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Vffa3uV3-Ium"
   },
   "source": [
    "En esta fase se seleccionarán, limpiarán y transformarán los datos para que sean adecuados al modelado. Se abordarán problemas como valores faltantes, duplicados o inconsistencias, y se construirán nuevas variables cuando sea necesario, con el objetivo de obtener un conjunto de datos listo para aplicar las técnicas de modelado."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GfiGj1kvr90b"
   },
   "source": [
    "## Codificación del texto a numéricos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_lFB_F5wsGqD"
   },
   "source": [
    "Se crea un diccionario que asigna a cada carácter único a un número entero, luego se crea un diccionario que asigna a cada carácter único a un número entero y se le asigna a cada carácter del texto su correspondiente número entero usando el diccionario."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "u4CnnZ8FsDIM"
   },
   "outputs": [],
   "source": [
    "char2idx = {u: i for i, u in enumerate(vocab)}\n",
    "idx2char = np.array(vocab)\n",
    "\n",
    "text_as_int = np.array([char2idx[c] for c in text])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JFosRgj3wxvJ"
   },
   "source": [
    "## Creación de secuencias para el entrenamiento"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D1UE47hvw3dS"
   },
   "source": [
    "Se divide el texto codificado en secuencias de 101 caracteres, los primeros 100 son usados como entrada y los siguientes 100 como objetivo, donde se prepararán así los datos en pares para entrenar una el modelo y este pueda aprender a predecir el siguiente carácter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "6zj7Be63w3Lp"
   },
   "outputs": [],
   "source": [
    "seq_length = 100\n",
    "examples_per_epoch = len(text) // (seq_length + 1)\n",
    "\n",
    "char_dataset = tf.data.Dataset.from_tensor_slices(text_as_int)\n",
    "\n",
    "sequences = char_dataset.batch(seq_length + 1, drop_remainder=True)\n",
    "\n",
    "def split_input_target(chunk):\n",
    "    input_text = chunk[:-1]\n",
    "    target_text = chunk[1:]\n",
    "    return input_text, target_text\n",
    "\n",
    "dataset = sequences.map(split_input_target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LEjQGmcO4OdR"
   },
   "source": [
    "## Preparación de los batches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6PtzvF2e4POp"
   },
   "source": [
    "Se organiza el dataset de secuencias para el entrenamiento, donde se barajan aleatoriamente los datos con **BUFFER_SIZE = 10000** para evitar que el modelo aprenda el orden natural del texto, luego se agrupan las secuencias en lotes de 64 para garantizar que todos los batches tengan el mismo tamaño se usará drop_remainder=True."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qNnKuiQ_4OGq"
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 128  # En lugar de 64\n",
    "BUFFER_SIZE = 10000\n",
    "\n",
    "dataset = dataset.shuffle(BUFFER_SIZE).batch(BATCH_SIZE, drop_remainder=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GmmuykopC_6P"
   },
   "source": [
    "*Pasar a Construcción del modelo LSTM [Fase 4]*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JlyoCUmm7IG8"
   },
   "source": [
    "# Fase 4 - Modelado"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TkfXL6rF-rNZ"
   },
   "source": [
    "En esta fase se seleccionarán los algoritmos de modelado más adecuados y se entrenarán los modelos utilizando el conjunto de datos preparado. Se ajustarán los parámetros de los modelos y se evaluarán los resultados preliminares para determinar qué técnicas ofrecen el mejor desempeño para cumplir con los objetivos planteados."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Xe6AeNAqDIoe"
   },
   "source": [
    "## Construcción del modelo LSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vqdWCKRLDOkA"
   },
   "source": [
    "Se define y construye el modelo LSTM, donde se definiran los parámetros:\n",
    "* vocab_size: El tamaño del vocabulario.\n",
    "* embedding_dim: La dimensión del espacio de representación vectorial para cada carácter.\n",
    "* rnn_units: El número de unidades en la capa LSTM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "N8L70F4SDORY"
   },
   "outputs": [],
   "source": [
    "vocab_size = len(vocab)\n",
    "embedding_dim = 128  # Reducido de 256\n",
    "rnn_units = 256      # Reducido de 1024"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jA9KdjbYDYyE"
   },
   "source": [
    "Se define la función la cual devuelve un modelo secuencial de Keras compuesto por una capa de entrada, la cual es necesaria para modelos stateful, una capa de Embedding, la cual transforma índices de caracteres en vectores densos, una capa LSTM stateful, con la que se generará una predicción por carácter, una capa Dropout del 25% para reducir el sobreajuste, una capa Dense final que entrega la probabilidad de cada carácter posible en la salida y se instancia el modelo con el batch size."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3zlXFuC1GOXX"
   },
   "source": [
    "* *Capa de entrada: Se especifica explicitamente el tamaño del batch y de la secuencia esperada por el modelo, esto ya que corresponde a un modelo stateful, donde se requiere conocer de antemano el tamaño del batch porque el estado de la LSTM se mantiene entre batches.*\n",
    "* *Capa de Embedding: Es una capa de proyección que toma índices enteros y los transforma en vectores densos de números realesw, esto debido a que el embedding aprende una representación vectorial útil de cada carácter.*\n",
    "* *Capa LSTM: Esta es el núcleo del modelo, la LSTM procesará la secuencia de vectores y generará una salida por cada paso de tiempo.*\n",
    "* *Dropout: Esta técnica de regularización desactiva aleatoriamente un porcentaje de neuronas durante el entrenamiento, lo cual evita que el modelo se sobreajuste a los datos de entrenamiento y ayuda a generalizar mejor.*\n",
    "* *Capa Dense: Esta capa densa toma la salida de la LSTM y genera un vector de probabilidades sobre todos los caracteres posibles del vocabulario, esta tiene una salida la cual cuenta con un tamaño igual al número de caracteres únicos.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 183
    },
    "id": "tlLB6CcIDYfh",
    "outputId": "3d88368c-7ae4-4695-db02-ba2737bf2d75"
   },
   "outputs": [],
   "source": [
    "def build_model(vocab_size, embedding_dim, rnn_units, batch_size):\n",
    "    return tf.keras.Sequential([\n",
    "        tf.keras.layers.Input(batch_shape=(batch_size, None)),\n",
    "        tf.keras.layers.Embedding(vocab_size, embedding_dim),\n",
    "        # Usamos LSTM con mejor inicialización y optimizada para GPU\n",
    "        tf.keras.layers.LSTM(rnn_units, \n",
    "                          return_sequences=True, \n",
    "                          stateful=True, \n",
    "                          recurrent_initializer='glorot_uniform',\n",
    "                          recurrent_activation='sigmoid',  # Más eficiente que 'tanh'\n",
    "                          implementation=2),  # Implementación más optimizada\n",
    "        tf.keras.layers.Dropout(0.2),  # Reducido de 0.25\n",
    "        tf.keras.layers.Dense(vocab_size)\n",
    "    ])\n",
    "\n",
    "model = build_model(vocab_size, embedding_dim, rnn_units, BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KFoP2eBII_Os"
   },
   "source": [
    "## Compilación del modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Mvt4UUIPI_Cu"
   },
   "source": [
    "Se define una función de pérdida personalizada adecuada para clasificación multi-clase con etiquetas enteras, luego se compila utilizando el optimizador Adam, la función de pérdida y la métrica de precisión."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "P1pO85tjI-rk"
   },
   "outputs": [],
   "source": [
    "def loss(labels, logits):\n",
    "    return tf.keras.losses.sparse_categorical_crossentropy(labels, logits, from_logits=True)\n",
    "\n",
    "# Learning rate schedule para convergencia más rápida\n",
    "initial_learning_rate = 0.002  # Un poco más alto para aprender más rápido inicialmente\n",
    "lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n",
    "    initial_learning_rate,\n",
    "    decay_steps=1000,\n",
    "    decay_rate=0.9,\n",
    "    staircase=True)\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=lr_schedule)\n",
    "\n",
    "model.compile(\n",
    "    optimizer=optimizer,\n",
    "    loss=loss,\n",
    "    metrics=[\n",
    "        tf.keras.metrics.SparseCategoricalAccuracy(name=\"accuracy\")\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2SEm4dsVJybq"
   },
   "source": [
    "## Separación de datos en entrenamiento y validación"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dfgBaelwJyLE"
   },
   "source": [
    "Se calcula el número total de batches y se divide el dataset en un 80%-20% para el entrenamiento y la validación respectivamente, buscando evaluar el modelo con datos no vistos en su entrenamiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wiIasfNpJxOU"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dataset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m total_batches \u001b[38;5;241m=\u001b[39m \u001b[43mdataset\u001b[49m\u001b[38;5;241m.\u001b[39mcardinality()\u001b[38;5;241m.\u001b[39mnumpy()\n\u001b[0;32m      2\u001b[0m train_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(\u001b[38;5;241m0.8\u001b[39m \u001b[38;5;241m*\u001b[39m total_batches)\n\u001b[0;32m      4\u001b[0m train_dataset \u001b[38;5;241m=\u001b[39m dataset\u001b[38;5;241m.\u001b[39mtake(train_size)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'dataset' is not defined"
     ]
    }
   ],
   "source": [
    "total_batches = dataset.cardinality().numpy()\n",
    "train_size = int(0.8 * total_batches)\n",
    "\n",
    "train_dataset = dataset.take(train_size)\n",
    "val_dataset = dataset.skip(train_size)\n",
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "train_dataset = train_dataset.prefetch(AUTOTUNE)\n",
    "val_dataset = val_dataset.prefetch(AUTOTUNE)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Phwjw0biKL6t"
   },
   "source": [
    "## Entrenamiento del modelo con los callbacks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i1wJsRsXKLuG"
   },
   "source": [
    "Se entrena el modelo por 20 épocas con dos callbacks importantes ModelCheckpoint, el cual guarda los pesos del modelo por época, lo que permite retomar el entrenamiento si se interrumpe y conserva el mejor modelo EarlyStopping, el cual detiene el entrenamiento si la precisión en validación no mejora tras 2 épocas, restaurando automáticamente los mejores pesos. Luego se entrena con los datasets ya preparados y separados (entrenamiento y validación) y guarda el historial de métricas para análisis posterior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2WiYiu1FKLXO"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "186/268 [===================>..........] - ETA: 2:17 - loss: 2.3940 - accuracy: 0.3032"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 16\u001b[0m\n\u001b[1;32m      9\u001b[0m earlystop_callback \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mcallbacks\u001b[38;5;241m.\u001b[39mEarlyStopping(\n\u001b[1;32m     10\u001b[0m     monitor\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_accuracy\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m     11\u001b[0m     patience\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m,\n\u001b[1;32m     12\u001b[0m     restore_best_weights\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m     13\u001b[0m )\n\u001b[1;32m     15\u001b[0m EPOCHS \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m20\u001b[39m\n\u001b[0;32m---> 16\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     17\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_dataset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     18\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_dataset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     19\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mEPOCHS\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     20\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mcheckpoint_callback\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mearlystop_callback\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m     21\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/keras/src/engine/training.py:1807\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1799\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[1;32m   1800\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1801\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1804\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m   1805\u001b[0m ):\n\u001b[1;32m   1806\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m-> 1807\u001b[0m     tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1808\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[1;32m   1809\u001b[0m         context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:832\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    829\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    831\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 832\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    834\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    835\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:868\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    865\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m    866\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m    867\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[0;32m--> 868\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtracing_compilation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    869\u001b[0m \u001b[43m      \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_no_variable_creation_config\u001b[49m\n\u001b[1;32m    870\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    871\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variable_creation_config \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    872\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[1;32m    873\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[1;32m    874\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:139\u001b[0m, in \u001b[0;36mcall_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    137\u001b[0m bound_args \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mbind(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    138\u001b[0m flat_inputs \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39munpack_inputs(bound_args)\n\u001b[0;32m--> 139\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[1;32m    140\u001b[0m \u001b[43m    \u001b[49m\u001b[43mflat_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\n\u001b[1;32m    141\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py:1323\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[1;32m   1319\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1320\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1321\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1322\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1323\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_preflattened\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1324\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1325\u001b[0m     args,\n\u001b[1;32m   1326\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1327\u001b[0m     executing_eagerly)\n\u001b[1;32m   1328\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:216\u001b[0m, in \u001b[0;36mAtomicFunction.call_preflattened\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mcall_preflattened\u001b[39m(\u001b[38;5;28mself\u001b[39m, args: Sequence[core\u001b[38;5;241m.\u001b[39mTensor]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m    215\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 216\u001b[0m   flat_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    217\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mpack_output(flat_outputs)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:251\u001b[0m, in \u001b[0;36mAtomicFunction.call_flat\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    249\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m record\u001b[38;5;241m.\u001b[39mstop_recording():\n\u001b[1;32m    250\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[0;32m--> 251\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_bound_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    252\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    253\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    254\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction_type\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflat_outputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    256\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    257\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m make_call_op_in_graph(\n\u001b[1;32m    258\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    259\u001b[0m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[1;32m    260\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mfunction_call_options\u001b[38;5;241m.\u001b[39mas_attrs(),\n\u001b[1;32m    261\u001b[0m     )\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/tensorflow/python/eager/context.py:1486\u001b[0m, in \u001b[0;36mContext.call_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1484\u001b[0m cancellation_context \u001b[38;5;241m=\u001b[39m cancellation\u001b[38;5;241m.\u001b[39mcontext()\n\u001b[1;32m   1485\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1486\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1487\u001b[0m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1488\u001b[0m \u001b[43m      \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1489\u001b[0m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensor_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1490\u001b[0m \u001b[43m      \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1491\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1492\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1493\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1494\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m   1495\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m   1496\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1500\u001b[0m       cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_context,\n\u001b[1;32m   1501\u001b[0m   )\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/tensorflow/python/eager/execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     54\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "checkpoint_dir = './training_checkpoints'\n",
    "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt_{epoch}.weights.h5\")\n",
    "\n",
    "checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_prefix,\n",
    "    save_weights_only=True,\n",
    "    save_freq=5 * len(train_dataset)  # Guardar cada 5 épocas en lugar de cada época\n",
    ")\n",
    "\n",
    "earlystop_callback = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='val_accuracy',\n",
    "    patience=3,  # Aumentado para dar más tiempo para alcanzar el objetivo\n",
    "    restore_best_weights=True\n",
    ")\n",
    "\n",
    "# Agregar TensorBoard para monitoreo de rendimiento\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(\n",
    "    log_dir='./logs',\n",
    "    histogram_freq=1,\n",
    "    profile_batch='500,520'  # Perfilar algunos batches para analizar rendimiento\n",
    ")\n",
    "\n",
    "EPOCHS = 20\n",
    "history = model.fit(\n",
    "    train_dataset,\n",
    "    validation_data=val_dataset,\n",
    "    epochs=EPOCHS,\n",
    "    callbacks=[checkpoint_callback, earlystop_callback, tensorboard_callback]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ql9bUgHRLFd-"
   },
   "source": [
    "*Se pasa a Visualización de las métricas de entrenamiento y validación [Fase 5]*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-0OZ561h7IhY"
   },
   "source": [
    "# Fase 5 - Evaluación"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "81znbA-s-7cM"
   },
   "source": [
    "En la fase de evaluación se analizará el rendimiento de los modelos desarrollados, comparándolos con los objetivos del negocio para asegurar que sean útiles y precisos. Se tomará en cuenta la validez de los resultados, se decidirá si es necesario ajustar los modelos o si están listos para su implementación."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YKfEcWQULA1E"
   },
   "source": [
    "## Visualización de las métricas de entrenamiento y validación"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vxZ2x26ILBVm"
   },
   "source": [
    "Se analiza el rendimiento del modelo LSTM visualizando gráficamente la evolución de la pérdida y la precisión durante las épocas de entrenamiento y validación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ktiq6_QCLBkM"
   },
   "outputs": [],
   "source": [
    "def plot_training_history(history):\n",
    "    acc = history.history['accuracy']\n",
    "    val_acc = history.history['val_accuracy']\n",
    "    loss = history.history['loss']\n",
    "    val_loss = history.history['val_loss']\n",
    "    epochs_range = range(len(acc))\n",
    "\n",
    "    plt.figure(figsize=(14, 5))\n",
    "\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(epochs_range, acc, label='Entrenamiento')\n",
    "    plt.plot(epochs_range, val_acc, label='Validación')\n",
    "    plt.title('Precisión durante el entrenamiento')\n",
    "    plt.xlabel('Épocas')\n",
    "    plt.ylabel('Precisión')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(epochs_range, loss, label='Entrenamiento')\n",
    "    plt.plot(epochs_range, val_loss, label='Validación')\n",
    "    plt.title('Pérdida durante el entrenamiento')\n",
    "    plt.xlabel('Épocas')\n",
    "    plt.ylabel('Pérdida')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "plot_training_history(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OLabmp-7MAW8"
   },
   "source": [
    "## Generación de una palabra"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D7K3C88jMAJ-"
   },
   "source": [
    "Se crea una función que genera una palabra de forma carácter por carácter, donde se transforma la entrada en índices, se reinicia el estado de la LSTM, y en cada paso predice el siguiente carácter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vjABEnQMMArE"
   },
   "outputs": [],
   "source": [
    "def generate_word(model, start_char, temperature=1.0, max_chars=30):\n",
    "    input_eval = [char2idx[c] for c in start_char.lower() if c in char2idx]\n",
    "    input_eval = tf.expand_dims(input_eval, 0)\n",
    "    model.layers[1].reset_states()\n",
    "\n",
    "    word = start_char\n",
    "    for _ in range(max_chars):\n",
    "        predictions = model(input_eval)\n",
    "        predictions = tf.squeeze(predictions, 0) / temperature\n",
    "        predicted_id = tf.random.categorical(predictions, num_samples=1)[-1, 0].numpy()\n",
    "\n",
    "        next_char = idx2char[predicted_id]\n",
    "        word += next_char\n",
    "\n",
    "        if next_char == ' ':\n",
    "            break\n",
    "        input_eval = tf.expand_dims([predicted_id], 0)\n",
    "\n",
    "    return word.strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4j0DzFLsMuVZ"
   },
   "source": [
    "## Generación de una frase"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "87ElZ0GaMvLh"
   },
   "source": [
    "Se crea una función que genera una frase completa construyendo palabra por palabra en un rango definido (temperature indica que tan creativo o tradicional será lo generado)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qAid1-MMMveK"
   },
   "outputs": [],
   "source": [
    "def generate_phrase(model, start_word, temperature=1.0, max_words=10):\n",
    "    current_input = start_word\n",
    "    phrase = start_word.strip()\n",
    "\n",
    "    for _ in range(max_words - 1):\n",
    "        next_word = generate_word(model, current_input[-1], temperature=temperature)\n",
    "        phrase += ' ' + next_word\n",
    "        current_input = next_word\n",
    "\n",
    "    return phrase"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uQfrWf2fM8ub"
   },
   "source": [
    "## Evaluación de la generación de palabras y frases"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aaTB7a2DM9OL"
   },
   "source": [
    "* La función generate_word(model, 'a') genera una palabra comenzando desde la letra 'a'.\n",
    "\n",
    "* La función generate_word(model, palabra_inicial[-1]) genera una palabra a partir del último carácter de la palabra \"don\".\n",
    "\n",
    "* La función generate_phrase(model, \"caballo\", temperature=0.8): genera una frase entera palabra por palabra, empezando con la palabra \"caballo\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wj8rBQTkM9fl"
   },
   "outputs": [],
   "source": [
    "print(\"Palabra generada desde letra 'a':\", generate_word(model, 'a'))\n",
    "\n",
    "palabra_inicial = \"don\"\n",
    "nueva_palabra = generate_word(model, palabra_inicial[-1])\n",
    "print(f\"Palabra generada desde la última letra de '{palabra_inicial}':\", nueva_palabra)\n",
    "\n",
    "print(\"Frase generada desde 'caballo':\")\n",
    "print(generate_phrase(model, \"caballo\", temperature=0.8))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0_RQiwip8Czg"
   },
   "source": [
    "# Fase 6 - Implementación"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "K4mTGDdo_VHd"
   },
   "source": [
    "En esta fase los modelos serán implementados en un entorno productivo para su uso real. Se generarán reportes detallados sobre los resultados y se establecerá un plan de mantenimiento y actualización periódica para asegurar la continua eficacia del modelo en el tiempo."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
