{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "99a477ac",
   "metadata": {},
   "source": [
    "# Fine-tuning MobileNetV2 on CIFAR-100\n",
    "This notebook continues training a MobileNetV2-based model that has reached ~69.2% validation accuracy, with the goal of pushing it past 70%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b8bc3c53",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-15 17:48:13.413984: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-04-15 17:48:13.458946: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2025-04-15 17:48:13.458988: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2025-04-15 17:48:13.460835: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-04-15 17:48:13.470332: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-04-15 17:48:13.471050: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-04-15 17:48:14.445551: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras import layers, models, optimizers, regularizers\n",
    "from tensorflow.keras.applications import MobileNetV2\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "import os\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8e83145",
   "metadata": {},
   "source": [
    "## Load previous best model and prepare dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "55d69ed3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load best model so far\n",
    "model = load_model('checkpoints/mobilenetv2_cifar100_best.h5')\n",
    "\n",
    "# Prepare data generators\n",
    "IMG_SIZE = 96\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.cifar100.load_data()\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    horizontal_flip=True,\n",
    "    zoom_range=0.2\n",
    ")\n",
    "\n",
    "train_gen = train_datagen.flow(x_train, tf.keras.utils.to_categorical(y_train, 100), batch_size=BATCH_SIZE)\n",
    "val_gen = ImageDataGenerator().flow(x_test, tf.keras.utils.to_categorical(y_test, 100), batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9924f1f6",
   "metadata": {},
   "source": [
    "## Fine-tuning the last 40 layers of MobileNetV2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cb9960cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encontrar la capa MobileNetV2 dentro del modelo\n",
    "base_model = None\n",
    "for layer in model.layers:\n",
    "    if isinstance(layer, tf.keras.Model) and layer.name.startswith('mobilenetv2'):\n",
    "        base_model = layer\n",
    "        break\n",
    "\n",
    "# Asegurarse de que encontramos MobileNetV2\n",
    "if base_model is not None:\n",
    "    base_model.trainable = True\n",
    "    # Congelar las primeras capas (ajustable)\n",
    "    for layer in base_model.layers[:-40]:\n",
    "        layer.trainable = False\n",
    "else:\n",
    "    raise ValueError(\"No se encontrÃ³ MobileNetV2 en el modelo cargado.\")\n",
    "\n",
    "# Recompilar el modelo\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4),\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d038791",
   "metadata": {},
   "source": [
    "## Continue training with early stopping and learning rate scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "818e66ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "782/782 [==============================] - ETA: 0s - loss: 3.7149 - accuracy: 0.1350"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/site-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 [==============================] - 52s 61ms/step - loss: 3.7149 - accuracy: 0.1350 - val_loss: 2.8900 - val_accuracy: 0.2573 - lr: 1.0000e-04\n",
      "Epoch 2/30\n",
      "782/782 [==============================] - 44s 57ms/step - loss: 3.1959 - accuracy: 0.2189 - val_loss: 2.6103 - val_accuracy: 0.3251 - lr: 1.0000e-04\n",
      "Epoch 3/30\n",
      "782/782 [==============================] - 42s 54ms/step - loss: 2.9748 - accuracy: 0.2643 - val_loss: 2.5272 - val_accuracy: 0.3553 - lr: 1.0000e-04\n",
      "Epoch 4/30\n",
      "604/782 [======================>.......] - ETA: 8s - loss: 2.8628 - accuracy: 0.2913"
     ]
    }
   ],
   "source": [
    "# Callbacks\n",
    "checkpoint_cb = ModelCheckpoint('checkpoints/mobilenetv2_finetuned_best.h5', save_best_only=True)\n",
    "early_stop_cb = EarlyStopping(patience=10, restore_best_weights=True)\n",
    "lr_cb = ReduceLROnPlateau(factor=0.5, patience=3, min_lr=1e-6)\n",
    "\n",
    "# Train more epochs\n",
    "history = model.fit(\n",
    "    train_gen,\n",
    "    validation_data=val_gen,\n",
    "    epochs=30,\n",
    "    callbacks=[checkpoint_cb, early_stop_cb, lr_cb],\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67266ff3",
   "metadata": {},
   "source": [
    "## Final evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebe0b7a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model('checkpoints/mobilenetv2_finetuned_best.h5')\n",
    "loss, acc = model.evaluate(val_gen)\n",
    "print(f\"Final Validation Loss: {loss:.4f}\")\n",
    "print(f\"Final Validation Accuracy: {acc:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
