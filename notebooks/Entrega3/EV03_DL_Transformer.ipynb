{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "52413683",
   "metadata": {},
   "source": [
    "# Análisis de Negocio"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e10e06ec",
   "metadata": {},
   "source": [
    "**Objetivo del Modelo:**\n",
    "El modelo está diseñado para generar texto similar al de \"Don Quijote de la Mancha\" utilizando una arquitectura Transformer. Sus aplicaciones potenciales incluyen:\n",
    "- Generación de contenido: Crear textos literarios o inspirados en obras clásicas con mayor coherencia.\n",
    "- Asistencia a escritores: Proporcionar ideas o continuaciones de frases con mejor comprensión del contexto.\n",
    "- Educación: Enseñar sobre arquitecturas de NLP modernas y generación de lenguaje natural.\n",
    "\n",
    "**Ventajas:**\n",
    "- Paralelización: A diferencia de RNN/LSTM, los Transformers pueden procesar todas las palabras simultáneamente.\n",
    "- Atención global: Capturan dependencias de largo alcance mejor que los modelos LSTM.\n",
    "- Escalabilidad: Pueden escalarse a conjuntos de datos más grandes y modelos más profundos.\n",
    "- Flexibilidad: Se adaptan a diferentes tareas de NLP con mínimos cambios arquitectónicos.\n",
    "\n",
    "**Limitaciones:**\n",
    "- Complejidad computacional: Requieren más recursos para entrenar que los modelos LSTM.\n",
    "- Tamaño del modelo: Generalmente son más grandes en términos de parámetros.\n",
    "- Datos de entrenamiento: Necesitan conjuntos de datos extensos para alcanzar su máximo potencial.\n",
    "- Tiempo de inferencia: Pueden ser más lentos durante la inferencia debido a su complejidad.\n",
    "\n",
    "**Oportunidades:**\n",
    "- Transfer Learning: Posibilidad de utilizar modelos pre-entrenados como base.\n",
    "- Multilingüismo: Gran capacidad para trabajar con múltiples idiomas.\n",
    "- Combinación con otras técnicas: Posibilidad de incorporar técnicas como beam search para mejorar la generación.\n",
    "\n",
    "**Riesgos:**\n",
    "- Sobreajuste: Con tantos parámetros, existe riesgo de memorizar en lugar de generalizar.\n",
    "- Uso ético: La generación de texto más coherente aumenta el riesgo de generar contenido engañoso.\n",
    "- Recursos computacionales: El entrenamiento e implementación requieren considerable potencia de cómputo."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70edcceb",
   "metadata": {},
   "source": [
    "# Cargar y preprocesar el texto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "9315416b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Longitud del texto: 2168460 caracteres\n",
      "Número total de oraciones: 9750\n",
      "Ejemplo de una oración:\n",
      "pues estadme atento y veréis cómo, en un abrir y cerrar de ojos, confundo todas vuestras dificultades y remedio todas las faltas que decís que os suspenden y acobardan para dejar de sacar a la luz del mundo la historia de vuestro famoso don quijote, luz y espejo de toda la caballería andante\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "import re\n",
    "\n",
    "path = tf.keras.utils.get_file('quijote.txt', 'https://www.gutenberg.org/files/2000/2000-0.txt')\n",
    "text = open(path, 'rb').read().decode(encoding='utf-8').lower()\n",
    "\n",
    "print(f'Longitud del texto: {len(text)} caracteres')\n",
    "\n",
    "# Limpieza del texto\n",
    "text = re.sub(r'\\s+', ' ', text)\n",
    "text = re.sub(r'[^a-záéíóúüñ .,;:¿?¡!\"-]', '', text)\n",
    "\n",
    "# Dividir el texto en oraciones para el transformer\n",
    "sentences = re.split(r'[.!?]+', text)\n",
    "sentences = [sentence.strip() for sentence in sentences if len(sentence.strip()) > 10]\n",
    "\n",
    "print(f'Número total de oraciones: {len(sentences)}')\n",
    "print(f'Ejemplo de una oración:\\n{sentences[42]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "724f161a",
   "metadata": {},
   "source": [
    "# Tokenización para el modelo Transformer\n",
    "\n",
    "A diferencia del modelo LSTM que trabajaba a nivel de caracteres, nuestro Transformer trabajará a nivel de palabras (tokens), lo que le permitirá capturar mejor el contexto semántico."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "cd999149",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tamaño del vocabulario: 10002 palabras\n"
     ]
    }
   ],
   "source": [
    "# Crear tokenizador a nivel de palabras\n",
    "tokenizer = tf.keras.preprocessing.text.Tokenizer(num_words=10000, oov_token=\"<UNK>\")\n",
    "tokenizer.fit_on_texts(sentences)\n",
    "\n",
    "# Añadir tokens especiales\n",
    "vocab_size = min(len(tokenizer.word_index) + 1, 10000)\n",
    "START_TOKEN = vocab_size\n",
    "END_TOKEN = vocab_size + 1\n",
    "vocab_size += 2  # Actualizar para incluir tokens especiales\n",
    "\n",
    "print(f'Tamaño del vocabulario: {vocab_size} palabras')\n",
    "\n",
    "# Convertir oraciones a secuencias\n",
    "sequences = tokenizer.texts_to_sequences(sentences)\n",
    "\n",
    "# Añadir tokens de inicio y fin\n",
    "sequences_with_tokens = []\n",
    "for seq in sequences:\n",
    "    sequences_with_tokens.append([START_TOKEN] + seq + [END_TOKEN])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4453c111-3042-4d61-8d55-545406bbd2a9",
   "metadata": {},
   "source": [
    "## Preparación de datos con manejo de memoria"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "19fc7db2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Limitado a 2000 secuencias aleatorias\n",
      "X_train: (1600, 99), y_train: (1600, 99)\n",
      "X_val: (400, 99), y_val: (400, 99)\n"
     ]
    }
   ],
   "source": [
    "# Limitar cantidad de secuencias para evitar problemas de memoria\n",
    "MAX_SAMPLES = 2000  # Ajusta según tu RAM disponible\n",
    "if len(sequences_with_tokens) > MAX_SAMPLES:\n",
    "    import random\n",
    "    random.seed(42)  # Para reproducibilidad\n",
    "    sequences_with_tokens = random.sample(sequences_with_tokens, MAX_SAMPLES)\n",
    "    print(f'Limitado a {MAX_SAMPLES} secuencias aleatorias')\n",
    "\n",
    "# Configuración más ligera\n",
    "MAX_SEQUENCE_LENGTH = 100\n",
    "BATCH_SIZE = 32\n",
    "BUFFER_SIZE = 1000\n",
    "\n",
    "# Truncar/rellenar secuencias\n",
    "def pad_sequences_custom(sequences, maxlen):\n",
    "    padded = tf.keras.preprocessing.sequence.pad_sequences(\n",
    "        sequences, \n",
    "        maxlen=maxlen,\n",
    "        padding='post',\n",
    "        truncating='post'  # Truncar secuencias largas\n",
    "    )\n",
    "    return padded\n",
    "\n",
    "# Crear pares de entrada/salida\n",
    "padded_seqs = pad_sequences_custom(sequences_with_tokens, MAX_SEQUENCE_LENGTH)\n",
    "input_seqs = padded_seqs[:, :-1]  # Todo menos el último token\n",
    "target_seqs = padded_seqs[:, 1:]  # Todo menos el primer token\n",
    "\n",
    "# División train/val con formato correcto\n",
    "train_size = int(0.8 * len(input_seqs))\n",
    "X_train = input_seqs[:train_size]\n",
    "X_val = input_seqs[train_size:]\n",
    "y_train = target_seqs[:train_size]\n",
    "y_val = target_seqs[train_size:]\n",
    "\n",
    "print(f'X_train: {X_train.shape}, y_train: {y_train.shape}')\n",
    "print(f'X_val: {X_val.shape}, y_val: {y_val.shape}')\n",
    "\n",
    "# Crear datasets con prefetch para mejor rendimiento\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((X_train, y_train))\n",
    "train_dataset = train_dataset.shuffle(BUFFER_SIZE).batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "val_dataset = tf.data.Dataset.from_tensor_slices((X_val, y_val))\n",
    "val_dataset = val_dataset.batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "464571f0-84a8-46dd-88cf-142207052369",
   "metadata": {},
   "source": [
    "## Modelo Transformer ultra-ligero optimizado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "b11f6f46",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Configuración del modelo\n",
    "num_layers = 2\n",
    "d_model = 64\n",
    "num_heads = 2\n",
    "dff = 128\n",
    "dropout_rate = 0.1\n",
    "\n",
    "# Crear máscaras para el Transformer\n",
    "def create_padding_mask(seq):\n",
    "    mask = tf.cast(tf.math.equal(seq, 0), tf.float32)\n",
    "    return mask[:, tf.newaxis, tf.newaxis, :]  # (batch_size, 1, 1, seq_len)\n",
    "\n",
    "def create_look_ahead_mask(size):\n",
    "    mask = 1 - tf.linalg.band_part(tf.ones((size, size)), -1, 0)\n",
    "    return mask  # (size, size)\n",
    "\n",
    "def create_masks(inp, tar):\n",
    "    enc_padding_mask = create_padding_mask(inp)\n",
    "    dec_padding_mask = create_padding_mask(inp)\n",
    "    \n",
    "    look_ahead_mask = create_look_ahead_mask(tf.shape(tar)[1])\n",
    "    dec_target_padding_mask = create_padding_mask(tar)\n",
    "    combined_mask = tf.maximum(dec_target_padding_mask, look_ahead_mask)\n",
    "    \n",
    "    return enc_padding_mask, combined_mask, dec_padding_mask\n",
    "\n",
    "# Clase de atención escalada por producto punto\n",
    "def scaled_dot_product_attention(q, k, v, mask=None):\n",
    "    matmul_qk = tf.matmul(q, k, transpose_b=True)\n",
    "    \n",
    "    dk = tf.cast(tf.shape(k)[-1], tf.float32)\n",
    "    scaled_attention_logits = matmul_qk / tf.math.sqrt(dk)\n",
    "    \n",
    "    if mask is not None:\n",
    "        scaled_attention_logits += (mask * -1e9)\n",
    "    \n",
    "    attention_weights = tf.nn.softmax(scaled_attention_logits, axis=-1)\n",
    "    output = tf.matmul(attention_weights, v)\n",
    "    \n",
    "    return output\n",
    "\n",
    "# Clase de atención multi-cabezal\n",
    "class MultiHeadAttention(tf.keras.layers.Layer):\n",
    "    def __init__(self, d_model, num_heads):\n",
    "        super(MultiHeadAttention, self).__init__()\n",
    "        self.num_heads = num_heads\n",
    "        self.d_model = d_model\n",
    "        \n",
    "        assert d_model % self.num_heads == 0\n",
    "        \n",
    "        self.depth = d_model // self.num_heads\n",
    "        \n",
    "        self.wq = tf.keras.layers.Dense(d_model)\n",
    "        self.wk = tf.keras.layers.Dense(d_model)\n",
    "        self.wv = tf.keras.layers.Dense(d_model)\n",
    "        \n",
    "        self.dense = tf.keras.layers.Dense(d_model)\n",
    "        \n",
    "    def split_heads(self, x, batch_size):\n",
    "        x = tf.reshape(x, (batch_size, -1, self.num_heads, self.depth))\n",
    "        return tf.transpose(x, perm=[0, 2, 1, 3])\n",
    "        \n",
    "    def call(self, v, k, q, mask=None):\n",
    "        batch_size = tf.shape(q)[0]\n",
    "        \n",
    "        q = self.wq(q)\n",
    "        k = self.wk(k)\n",
    "        v = self.wv(v)\n",
    "        \n",
    "        q = self.split_heads(q, batch_size)\n",
    "        k = self.split_heads(k, batch_size)\n",
    "        v = self.split_heads(v, batch_size)\n",
    "        \n",
    "        scaled_attention = scaled_dot_product_attention(q, k, v, mask)\n",
    "        \n",
    "        scaled_attention = tf.transpose(scaled_attention, perm=[0, 2, 1, 3])\n",
    "        \n",
    "        concat_attention = tf.reshape(scaled_attention, (batch_size, -1, self.d_model))\n",
    "        \n",
    "        output = self.dense(concat_attention)\n",
    "            \n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e03bd641-4cfc-417e-bf8c-9254da7a89a0",
   "metadata": {},
   "source": [
    "## Implementación del resto del modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "41856977",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Codificación posicional\n",
    "class PositionalEncoding(tf.keras.layers.Layer):\n",
    "    def __init__(self, position, d_model):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        self.pos_encoding = self.positional_encoding(position, d_model)\n",
    "        \n",
    "    def get_angles(self, pos, i, d_model):\n",
    "        angle_rates = 1 / np.power(10000, (2 * (i // 2)) / np.float32(d_model))\n",
    "        return pos * angle_rates\n",
    "      \n",
    "    def positional_encoding(self, position, d_model):\n",
    "        angle_rads = self.get_angles(np.arange(position)[:, np.newaxis],\n",
    "                                      np.arange(d_model)[np.newaxis, :],\n",
    "                                      d_model)\n",
    "        \n",
    "        # Aplicar seno a índices pares\n",
    "        angle_rads[:, 0::2] = np.sin(angle_rads[:, 0::2])\n",
    "        \n",
    "        # Aplicar coseno a índices impares\n",
    "        angle_rads[:, 1::2] = np.cos(angle_rads[:, 1::2])\n",
    "            \n",
    "        pos_encoding = angle_rads[np.newaxis, ...]\n",
    "        \n",
    "        return tf.cast(pos_encoding, dtype=tf.float32)\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        return inputs + self.pos_encoding[:, :tf.shape(inputs)[1], :]\n",
    "\n",
    "# Feed Forward Network\n",
    "def point_wise_feed_forward_network(d_model, dff):\n",
    "    return tf.keras.Sequential([\n",
    "        tf.keras.layers.Dense(dff, activation='relu'),\n",
    "        tf.keras.layers.Dense(d_model)\n",
    "    ])\n",
    "\n",
    "# Capa de Encoder\n",
    "class EncoderLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self, d_model, num_heads, dff, rate=0.1):\n",
    "        super(EncoderLayer, self).__init__()\n",
    "\n",
    "        self.mha = MultiHeadAttention(d_model, num_heads)\n",
    "        self.ffn = point_wise_feed_forward_network(d_model, dff)\n",
    "\n",
    "        self.layernorm1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.layernorm2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "        \n",
    "        self.dropout1 = tf.keras.layers.Dropout(rate)\n",
    "        self.dropout2 = tf.keras.layers.Dropout(rate)\n",
    "    \n",
    "    def call(self, x, training, mask=None):\n",
    "        attn_output = self.mha(x, x, x, mask)\n",
    "        attn_output = self.dropout1(attn_output, training=training)\n",
    "        out1 = self.layernorm1(x + attn_output)\n",
    "        \n",
    "        ffn_output = self.ffn(out1)\n",
    "        ffn_output = self.dropout2(ffn_output, training=training)\n",
    "        out2 = self.layernorm2(out1 + ffn_output)\n",
    "        \n",
    "        return out2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bfa2d15-b050-4460-afc1-f675df263c41",
   "metadata": {},
   "source": [
    "## Modelo completo y función de entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "59a36bee-3785-4f60-bb9a-d156195cdd87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Capa de Decoder\n",
    "class DecoderLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self, d_model, num_heads, dff, rate=0.1):\n",
    "        super(DecoderLayer, self).__init__()\n",
    "\n",
    "        self.mha1 = MultiHeadAttention(d_model, num_heads)\n",
    "        self.mha2 = MultiHeadAttention(d_model, num_heads)\n",
    "\n",
    "        self.ffn = point_wise_feed_forward_network(d_model, dff)\n",
    "        \n",
    "        self.layernorm1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.layernorm2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.layernorm3 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "        \n",
    "        self.dropout1 = tf.keras.layers.Dropout(rate)\n",
    "        self.dropout2 = tf.keras.layers.Dropout(rate)\n",
    "        self.dropout3 = tf.keras.layers.Dropout(rate)\n",
    "    \n",
    "    def call(self, x, enc_output, training, look_ahead_mask=None, padding_mask=None):\n",
    "        attn1 = self.mha1(x, x, x, look_ahead_mask)\n",
    "        attn1 = self.dropout1(attn1, training=training)\n",
    "        out1 = self.layernorm1(attn1 + x)\n",
    "        \n",
    "        attn2 = self.mha2(enc_output, enc_output, out1, padding_mask)\n",
    "        attn2 = self.dropout2(attn2, training=training)\n",
    "        out2 = self.layernorm2(attn2 + out1)\n",
    "        \n",
    "        ffn_output = self.ffn(out2)\n",
    "        ffn_output = self.dropout3(ffn_output, training=training)\n",
    "        out3 = self.layernorm3(ffn_output + out2)\n",
    "        \n",
    "        return out3\n",
    "\n",
    "# Encoder\n",
    "# Encoder corregido\n",
    "class Encoder(tf.keras.layers.Layer):\n",
    "    def __init__(self, num_layers, d_model, num_heads, dff, input_vocab_size,\n",
    "                 maximum_position_encoding, rate=0.1):\n",
    "        super(Encoder, self).__init__()\n",
    "\n",
    "        self.d_model = d_model\n",
    "        self.num_layers = num_layers\n",
    "        \n",
    "        self.embedding = tf.keras.layers.Embedding(input_vocab_size, d_model)\n",
    "        self.pos_encoding = PositionalEncoding(maximum_position_encoding, d_model)\n",
    "\n",
    "        self.enc_layers = [\n",
    "            EncoderLayer(d_model, num_heads, dff, rate) \n",
    "            for _ in range(num_layers)]\n",
    "        \n",
    "        self.dropout = tf.keras.layers.Dropout(rate)\n",
    "            \n",
    "    def call(self, x, training, mask=None):\n",
    "        seq_len = tf.shape(x)[1]\n",
    "        \n",
    "        # Añadir embedding y codificación posicional\n",
    "        x = self.embedding(x)\n",
    "        x *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))\n",
    "        \n",
    "        # Aquí está el cambio clave\n",
    "        x = self.pos_encoding(x)\n",
    "\n",
    "        x = self.dropout(x, training=training)\n",
    "        \n",
    "        for i in range(self.num_layers):\n",
    "            x = self.enc_layers[i](x, training, mask)\n",
    "        \n",
    "        return x\n",
    "\n",
    "# Decoder corregido\n",
    "class Decoder(tf.keras.layers.Layer):\n",
    "    def __init__(self, num_layers, d_model, num_heads, dff, target_vocab_size,\n",
    "                 maximum_position_encoding, rate=0.1):\n",
    "        super(Decoder, self).__init__()\n",
    "\n",
    "        self.d_model = d_model\n",
    "        self.num_layers = num_layers\n",
    "        \n",
    "        self.embedding = tf.keras.layers.Embedding(target_vocab_size, d_model)\n",
    "        self.pos_encoding = PositionalEncoding(maximum_position_encoding, d_model)\n",
    "        \n",
    "        self.dec_layers = [\n",
    "            DecoderLayer(d_model, num_heads, dff, rate) \n",
    "            for _ in range(num_layers)]\n",
    "        self.dropout = tf.keras.layers.Dropout(rate)\n",
    "        \n",
    "    def call(self, x, enc_output, training, \n",
    "             look_ahead_mask=None, padding_mask=None):\n",
    "        seq_len = tf.shape(x)[1]\n",
    "        \n",
    "        x = self.embedding(x)\n",
    "        x *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))\n",
    "        \n",
    "        # Aquí está el cambio clave\n",
    "        x = self.pos_encoding(x)\n",
    "        \n",
    "        x = self.dropout(x, training=training)\n",
    "\n",
    "        for i in range(self.num_layers):\n",
    "            x = self.dec_layers[i](\n",
    "                x, enc_output, training, look_ahead_mask, padding_mask)\n",
    "        \n",
    "        return x\n",
    "\n",
    "# Modelo Transformer completo\n",
    "class TransformerLite(tf.keras.Model):\n",
    "    def __init__(self, num_layers, d_model, num_heads, dff, input_vocab_size, \n",
    "                 target_vocab_size, pe_input, pe_target, rate=0.1):\n",
    "        super(TransformerLite, self).__init__()\n",
    "\n",
    "        self.encoder = Encoder(num_layers, d_model, num_heads, dff, \n",
    "                               input_vocab_size, pe_input, rate)\n",
    "\n",
    "        self.decoder = Decoder(num_layers, d_model, num_heads, dff, \n",
    "                               target_vocab_size, pe_target, rate)\n",
    "\n",
    "        self.final_layer = tf.keras.layers.Dense(target_vocab_size)\n",
    "        \n",
    "    def call(self, inputs, training):\n",
    "        inp, tar = inputs\n",
    "        \n",
    "        enc_padding_mask, look_ahead_mask, dec_padding_mask = create_masks(inp, tar)\n",
    "        \n",
    "        enc_output = self.encoder(inp, training, enc_padding_mask)\n",
    "        \n",
    "        dec_output = self.decoder(tar, enc_output, training, \n",
    "                                 look_ahead_mask, dec_padding_mask)\n",
    "        \n",
    "        final_output = self.final_layer(dec_output)\n",
    "        \n",
    "        return final_output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d567a06-532d-4d0e-8e73-fc3b683b2c3d",
   "metadata": {},
   "source": [
    "## Configurar optimizador y métricas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "a5b26902-99cf-47fc-a56a-46d4fd694a08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creando Transformer ligero: 2 capas, dim=64, 2 cabezas\n"
     ]
    }
   ],
   "source": [
    "# Optimizador con learning rate simple (evitar custom scheduler para simplicidad)\n",
    "learning_rate = 0.0001\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate)\n",
    "\n",
    "# Función de pérdida con enmascaramiento para ignorar padding\n",
    "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(\n",
    "    from_logits=True, reduction='none')\n",
    "\n",
    "def loss_function(real, pred):\n",
    "    mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
    "    loss_ = loss_object(real, pred)\n",
    "    \n",
    "    mask = tf.cast(mask, dtype=loss_.dtype)\n",
    "    loss_ *= mask\n",
    "    \n",
    "    return tf.reduce_sum(loss_) / tf.reduce_sum(mask)\n",
    "\n",
    "# Métricas\n",
    "train_loss = tf.keras.metrics.Mean(name='train_loss')\n",
    "train_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name='train_accuracy')\n",
    "val_loss = tf.keras.metrics.Mean(name='val_loss')\n",
    "val_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name='val_accuracy')\n",
    "\n",
    "# Crear el modelo\n",
    "print(f\"Creando Transformer ligero: {num_layers} capas, dim={d_model}, {num_heads} cabezas\")\n",
    "transformer = TransformerLite(\n",
    "    num_layers=num_layers,\n",
    "    d_model=d_model,\n",
    "    num_heads=num_heads,\n",
    "    dff=dff,\n",
    "    input_vocab_size=vocab_size,\n",
    "    target_vocab_size=vocab_size,\n",
    "    pe_input=MAX_SEQUENCE_LENGTH,\n",
    "    pe_target=MAX_SEQUENCE_LENGTH,\n",
    "    rate=dropout_rate\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef4a74d5-0d77-4236-8651-e30a2d7ac35d",
   "metadata": {},
   "source": [
    "## Ciclo de entrenamiento con manejo de memoria"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "cda7e6da-9580-4e1d-89a7-2cd0002c4de3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Último checkpoint restaurado: ./transformer_lite_checkpoint/ckpt-1\n"
     ]
    }
   ],
   "source": [
    "# Configuración de checkpoint\n",
    "checkpoint_path = \"./transformer_lite_checkpoint\"\n",
    "checkpoint = tf.train.Checkpoint(transformer=transformer, optimizer=optimizer)\n",
    "checkpoint_manager = tf.train.CheckpointManager(checkpoint, checkpoint_path, max_to_keep=3)\n",
    "\n",
    "# Restaurar último checkpoint si existe\n",
    "if checkpoint_manager.latest_checkpoint:\n",
    "    checkpoint.restore(checkpoint_manager.latest_checkpoint)\n",
    "    print(f\"Último checkpoint restaurado: {checkpoint_manager.latest_checkpoint}\")\n",
    "\n",
    "# Funciones para entrenamiento y validación\n",
    "@tf.function\n",
    "def train_step(inp, tar):\n",
    "    # Dividir el objetivo (para teacher forcing)\n",
    "    tar_inp = tar[:, :-1]\n",
    "    tar_real = tar[:, 1:]\n",
    "    \n",
    "    # Crear máscaras necesarias\n",
    "    enc_padding_mask, combined_mask, dec_padding_mask = create_masks(inp, tar_inp)\n",
    "    \n",
    "    with tf.GradientTape() as tape:\n",
    "        # Obtener predicciones del modelo\n",
    "        predictions = transformer([inp, tar_inp], training=True)\n",
    "        \n",
    "        # Calcular pérdida\n",
    "        loss = loss_function(tar_real, predictions)\n",
    "    \n",
    "    # Calcular gradientes y aplicarlos\n",
    "    gradients = tape.gradient(loss, transformer.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(gradients, transformer.trainable_variables))\n",
    "    \n",
    "    # Actualizar métricas\n",
    "    train_loss(loss)\n",
    "    train_accuracy(tar_real, predictions)\n",
    "    \n",
    "    return loss\n",
    "\n",
    "@tf.function\n",
    "def val_step(inp, tar):\n",
    "    # Igual que train_step pero sin cálculo de gradientes\n",
    "    tar_inp = tar[:, :-1]\n",
    "    tar_real = tar[:, 1:]\n",
    "    \n",
    "    enc_padding_mask, combined_mask, dec_padding_mask = create_masks(inp, tar_inp)\n",
    "    \n",
    "    # Evaluar sin cálculo de gradientes\n",
    "    predictions = transformer([inp, tar_inp], training=False)\n",
    "    \n",
    "    # Calcular pérdida\n",
    "    loss = loss_function(tar_real, predictions)\n",
    "    \n",
    "    # Actualizar métricas\n",
    "    val_loss(loss)\n",
    "    val_accuracy(tar_real, predictions)\n",
    "    \n",
    "    return loss\n",
    "\n",
    "# Función de entrenamiento\n",
    "def train_model(epochs=EPOCHS):\n",
    "    print(\"\\n=== INICIANDO ENTRENAMIENTO DEL TRANSFORMER LIGERO ===\\n\")\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        start = time.time()\n",
    "        \n",
    "        # Reiniciar métricas\n",
    "        train_loss.reset_states()\n",
    "        train_accuracy.reset_states()\n",
    "        val_loss.reset_states()\n",
    "        val_accuracy.reset_states()\n",
    "        \n",
    "        # Recorrer batches de entrenamiento\n",
    "        for (batch, (inp, tar)) in enumerate(train_dataset):\n",
    "            train_step(inp, tar)\n",
    "            \n",
    "            # Limpiar memoria periódicamente\n",
    "            if batch % 10 == 0:\n",
    "                gc.collect()\n",
    "        \n",
    "        # Evaluar en conjunto de validación\n",
    "        for (inp, tar) in val_dataset:\n",
    "            val_step(inp, tar)\n",
    "        \n",
    "        # Guardar checkpoint\n",
    "        if (epoch + 1) % 5 == 0 or epoch == epochs - 1:\n",
    "            checkpoint_manager.save()\n",
    "        \n",
    "        print(f\"Época {epoch + 1}/{epochs}\")\n",
    "        print(f\"  Época {epoch + 1}: Train Loss {train_loss.result():.4f}, Val Loss {val_loss.result():.4f}\")\n",
    "        print(f\"  Tiempo: {time.time() - start:.2f}s\\n\")\n",
    "        \n",
    "        # Liberar memoria entre épocas\n",
    "        gc.collect()\n",
    "    \n",
    "    # Guardar checkpoint final\n",
    "    checkpoint_manager.save()\n",
    "    print(\"\\n=== ENTRENAMIENTO COMPLETADO ===\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f0695bb-649b-4102-bf5e-72c2986626d6",
   "metadata": {},
   "source": [
    "##  Función para generar texto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "95ff179b-003c-4644-8a9b-04a55ee8b371",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text(model, tokenizer, start_string, max_length=50, temperature=1.0):\n",
    "    # Tokenizar texto inicial\n",
    "    input_tokens = tokenizer.texts_to_sequences([start_string])[0]\n",
    "    \n",
    "    # Convertir a tensor\n",
    "    input_tensor = tf.convert_to_tensor([input_tokens], dtype=tf.int32)\n",
    "    \n",
    "    # Crear arreglo para almacenar el resultado\n",
    "    result = [t for t in input_tokens]\n",
    "    \n",
    "    for i in range(max_length):\n",
    "        # Preparar la entrada para el decoder\n",
    "        decoder_input = tf.convert_to_tensor([result], dtype=tf.int32)\n",
    "        \n",
    "        # Predicción\n",
    "        predictions = model([input_tensor, decoder_input], training=False)\n",
    "        \n",
    "        # Seleccionar último token predicho\n",
    "        predictions = predictions[:, -1:, :]\n",
    "        \n",
    "        # Aplicar temperatura para muestreo más diverso\n",
    "        if temperature != 1.0:\n",
    "            predictions = predictions / temperature\n",
    "            \n",
    "        # Seleccionar token con mayor probabilidad\n",
    "        predicted_id = tf.argmax(predictions, axis=-1)[0][0].numpy()\n",
    "        \n",
    "        # Agregar token al resultado\n",
    "        result.append(predicted_id)\n",
    "        \n",
    "        # Detener si predice el token END\n",
    "        if predicted_id == END_TOKEN:\n",
    "            break\n",
    "    \n",
    "    # Convertir tokens a texto\n",
    "    result_tokens = [t for t in result if t < len(tokenizer.word_index) + 1]\n",
    "    \n",
    "    # Obtener palabras correspondientes\n",
    "    index_to_word = {v: k for k, v in tokenizer.word_index.items()}\n",
    "    result_words = [index_to_word.get(t, '') for t in result_tokens]\n",
    "    \n",
    "    return ' '.join(result_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb8fb9ce-84cb-4d75-90e0-ebc8bbb1aa36",
   "metadata": {},
   "source": [
    "## Ejecución del entrenamiento y generación de texto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "49d10c45-d0e6-454a-90e8-5fefb31356af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== INICIANDO ENTRENAMIENTO DEL TRANSFORMER LIGERO ===\n",
      "\n",
      "WARNING:tensorflow:Detecting that an object or model or tf.train.Checkpoint is being deleted with unrestored values. See the following logs for the specific values in question. To silence these warnings, use `status.expect_partial()`. See https://www.tensorflow.org/api_docs/python/tf/train/Checkpoint#restorefor details about the status object returned by the restore function.\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).transformer.layer_with_weights-2.kernel\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).transformer.layer_with_weights-2.bias\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).transformer.layer_with_weights-0.layer_with_weights-0.embeddings\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).transformer.layer_with_weights-1.layer_with_weights-0.embeddings\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).transformer.layer_with_weights-0.layer_with_weights-1.layer_with_weights-1.gamma\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).transformer.layer_with_weights-0.layer_with_weights-1.layer_with_weights-1.beta\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).transformer.layer_with_weights-0.layer_with_weights-1.layer_with_weights-2.kernel\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).transformer.layer_with_weights-0.layer_with_weights-1.layer_with_weights-2.bias\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).transformer.layer_with_weights-0.layer_with_weights-1.layer_with_weights-3.kernel\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).transformer.layer_with_weights-0.layer_with_weights-1.layer_with_weights-3.bias\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).transformer.layer_with_weights-0.layer_with_weights-1.layer_with_weights-4.gamma\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).transformer.layer_with_weights-0.layer_with_weights-1.layer_with_weights-4.beta\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).transformer.layer_with_weights-0.layer_with_weights-2.layer_with_weights-1.gamma\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).transformer.layer_with_weights-0.layer_with_weights-2.layer_with_weights-1.beta\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).transformer.layer_with_weights-0.layer_with_weights-2.layer_with_weights-2.kernel\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).transformer.layer_with_weights-0.layer_with_weights-2.layer_with_weights-2.bias\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).transformer.layer_with_weights-0.layer_with_weights-2.layer_with_weights-3.kernel\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).transformer.layer_with_weights-0.layer_with_weights-2.layer_with_weights-3.bias\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).transformer.layer_with_weights-0.layer_with_weights-2.layer_with_weights-4.gamma\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).transformer.layer_with_weights-0.layer_with_weights-2.layer_with_weights-4.beta\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).transformer.layer_with_weights-1.layer_with_weights-1.layer_with_weights-1.gamma\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).transformer.layer_with_weights-1.layer_with_weights-1.layer_with_weights-1.beta\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).transformer.layer_with_weights-1.layer_with_weights-1.layer_with_weights-3.gamma\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).transformer.layer_with_weights-1.layer_with_weights-1.layer_with_weights-3.beta\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).transformer.layer_with_weights-1.layer_with_weights-1.layer_with_weights-4.kernel\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).transformer.layer_with_weights-1.layer_with_weights-1.layer_with_weights-4.bias\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).transformer.layer_with_weights-1.layer_with_weights-1.layer_with_weights-5.kernel\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).transformer.layer_with_weights-1.layer_with_weights-1.layer_with_weights-5.bias\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).transformer.layer_with_weights-1.layer_with_weights-1.layer_with_weights-6.gamma\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).transformer.layer_with_weights-1.layer_with_weights-1.layer_with_weights-6.beta\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).transformer.layer_with_weights-1.layer_with_weights-2.layer_with_weights-1.gamma\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).transformer.layer_with_weights-1.layer_with_weights-2.layer_with_weights-1.beta\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).transformer.layer_with_weights-1.layer_with_weights-2.layer_with_weights-3.gamma\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).transformer.layer_with_weights-1.layer_with_weights-2.layer_with_weights-3.beta\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).transformer.layer_with_weights-1.layer_with_weights-2.layer_with_weights-4.kernel\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).transformer.layer_with_weights-1.layer_with_weights-2.layer_with_weights-4.bias\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).transformer.layer_with_weights-1.layer_with_weights-2.layer_with_weights-5.kernel\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).transformer.layer_with_weights-1.layer_with_weights-2.layer_with_weights-5.bias\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).transformer.layer_with_weights-1.layer_with_weights-2.layer_with_weights-6.gamma\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).transformer.layer_with_weights-1.layer_with_weights-2.layer_with_weights-6.beta\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).transformer.layer_with_weights-0.layer_with_weights-1.layer_with_weights-0.wq.kernel\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).transformer.layer_with_weights-0.layer_with_weights-1.layer_with_weights-0.wq.bias\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).transformer.layer_with_weights-0.layer_with_weights-1.layer_with_weights-0.wk.kernel\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).transformer.layer_with_weights-0.layer_with_weights-1.layer_with_weights-0.wk.bias\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).transformer.layer_with_weights-0.layer_with_weights-1.layer_with_weights-0.wv.kernel\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).transformer.layer_with_weights-0.layer_with_weights-1.layer_with_weights-0.wv.bias\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).transformer.layer_with_weights-0.layer_with_weights-1.layer_with_weights-0.dense.kernel\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).transformer.layer_with_weights-0.layer_with_weights-1.layer_with_weights-0.dense.bias\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).transformer.layer_with_weights-0.layer_with_weights-2.layer_with_weights-0.wq.kernel\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).transformer.layer_with_weights-0.layer_with_weights-2.layer_with_weights-0.wq.bias\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).transformer.layer_with_weights-0.layer_with_weights-2.layer_with_weights-0.wk.kernel\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).transformer.layer_with_weights-0.layer_with_weights-2.layer_with_weights-0.wk.bias\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).transformer.layer_with_weights-0.layer_with_weights-2.layer_with_weights-0.wv.kernel\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).transformer.layer_with_weights-0.layer_with_weights-2.layer_with_weights-0.wv.bias\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).transformer.layer_with_weights-0.layer_with_weights-2.layer_with_weights-0.dense.kernel\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).transformer.layer_with_weights-0.layer_with_weights-2.layer_with_weights-0.dense.bias\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).transformer.layer_with_weights-1.layer_with_weights-1.layer_with_weights-0.wq.kernel\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).transformer.layer_with_weights-1.layer_with_weights-1.layer_with_weights-0.wq.bias\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).transformer.layer_with_weights-1.layer_with_weights-1.layer_with_weights-0.wk.kernel\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).transformer.layer_with_weights-1.layer_with_weights-1.layer_with_weights-0.wk.bias\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).transformer.layer_with_weights-1.layer_with_weights-1.layer_with_weights-0.wv.kernel\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).transformer.layer_with_weights-1.layer_with_weights-1.layer_with_weights-0.wv.bias\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).transformer.layer_with_weights-1.layer_with_weights-1.layer_with_weights-0.dense.kernel\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).transformer.layer_with_weights-1.layer_with_weights-1.layer_with_weights-0.dense.bias\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).transformer.layer_with_weights-1.layer_with_weights-1.layer_with_weights-2.wq.kernel\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).transformer.layer_with_weights-1.layer_with_weights-1.layer_with_weights-2.wq.bias\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).transformer.layer_with_weights-1.layer_with_weights-1.layer_with_weights-2.wk.kernel\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).transformer.layer_with_weights-1.layer_with_weights-1.layer_with_weights-2.wk.bias\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).transformer.layer_with_weights-1.layer_with_weights-1.layer_with_weights-2.wv.kernel\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).transformer.layer_with_weights-1.layer_with_weights-1.layer_with_weights-2.wv.bias\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).transformer.layer_with_weights-1.layer_with_weights-1.layer_with_weights-2.dense.kernel\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).transformer.layer_with_weights-1.layer_with_weights-1.layer_with_weights-2.dense.bias\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).transformer.layer_with_weights-1.layer_with_weights-2.layer_with_weights-0.wq.kernel\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).transformer.layer_with_weights-1.layer_with_weights-2.layer_with_weights-0.wq.bias\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).transformer.layer_with_weights-1.layer_with_weights-2.layer_with_weights-0.wk.kernel\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).transformer.layer_with_weights-1.layer_with_weights-2.layer_with_weights-0.wk.bias\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).transformer.layer_with_weights-1.layer_with_weights-2.layer_with_weights-0.wv.kernel\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).transformer.layer_with_weights-1.layer_with_weights-2.layer_with_weights-0.wv.bias\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).transformer.layer_with_weights-1.layer_with_weights-2.layer_with_weights-0.dense.kernel\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).transformer.layer_with_weights-1.layer_with_weights-2.layer_with_weights-0.dense.bias\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).transformer.layer_with_weights-1.layer_with_weights-2.layer_with_weights-2.wq.kernel\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).transformer.layer_with_weights-1.layer_with_weights-2.layer_with_weights-2.wq.bias\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).transformer.layer_with_weights-1.layer_with_weights-2.layer_with_weights-2.wk.kernel\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).transformer.layer_with_weights-1.layer_with_weights-2.layer_with_weights-2.wk.bias\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).transformer.layer_with_weights-1.layer_with_weights-2.layer_with_weights-2.wv.kernel\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).transformer.layer_with_weights-1.layer_with_weights-2.layer_with_weights-2.wv.bias\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).transformer.layer_with_weights-1.layer_with_weights-2.layer_with_weights-2.dense.kernel\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).transformer.layer_with_weights-1.layer_with_weights-2.layer_with_weights-2.dense.bias\n",
      "WARNING:tensorflow:Detecting that an object or model or tf.train.Checkpoint is being deleted with unrestored values. See the following logs for the specific values in question. To silence these warnings, use `status.expect_partial()`. See https://www.tensorflow.org/api_docs/python/tf/train/Checkpoint#restorefor details about the status object returned by the restore function.\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).transformer.layer_with_weights-2.kernel\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).transformer.layer_with_weights-2.bias\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).transformer.layer_with_weights-0.layer_with_weights-0.embeddings\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).transformer.layer_with_weights-1.layer_with_weights-0.embeddings\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).transformer.layer_with_weights-0.layer_with_weights-1.layer_with_weights-1.gamma\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).transformer.layer_with_weights-0.layer_with_weights-1.layer_with_weights-1.beta\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).transformer.layer_with_weights-0.layer_with_weights-1.layer_with_weights-2.kernel\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).transformer.layer_with_weights-0.layer_with_weights-1.layer_with_weights-2.bias\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).transformer.layer_with_weights-0.layer_with_weights-1.layer_with_weights-3.kernel\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).transformer.layer_with_weights-0.layer_with_weights-1.layer_with_weights-3.bias\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).transformer.layer_with_weights-0.layer_with_weights-1.layer_with_weights-4.gamma\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).transformer.layer_with_weights-0.layer_with_weights-1.layer_with_weights-4.beta\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).transformer.layer_with_weights-0.layer_with_weights-2.layer_with_weights-1.gamma\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).transformer.layer_with_weights-0.layer_with_weights-2.layer_with_weights-1.beta\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).transformer.layer_with_weights-0.layer_with_weights-2.layer_with_weights-2.kernel\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).transformer.layer_with_weights-0.layer_with_weights-2.layer_with_weights-2.bias\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).transformer.layer_with_weights-0.layer_with_weights-2.layer_with_weights-3.kernel\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).transformer.layer_with_weights-0.layer_with_weights-2.layer_with_weights-3.bias\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).transformer.layer_with_weights-0.layer_with_weights-2.layer_with_weights-4.gamma\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).transformer.layer_with_weights-0.layer_with_weights-2.layer_with_weights-4.beta\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).transformer.layer_with_weights-1.layer_with_weights-1.layer_with_weights-1.gamma\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).transformer.layer_with_weights-1.layer_with_weights-1.layer_with_weights-1.beta\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).transformer.layer_with_weights-1.layer_with_weights-1.layer_with_weights-3.gamma\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).transformer.layer_with_weights-1.layer_with_weights-1.layer_with_weights-3.beta\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).transformer.layer_with_weights-1.layer_with_weights-1.layer_with_weights-4.kernel\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).transformer.layer_with_weights-1.layer_with_weights-1.layer_with_weights-4.bias\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).transformer.layer_with_weights-1.layer_with_weights-1.layer_with_weights-5.kernel\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).transformer.layer_with_weights-1.layer_with_weights-1.layer_with_weights-5.bias\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).transformer.layer_with_weights-1.layer_with_weights-1.layer_with_weights-6.gamma\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).transformer.layer_with_weights-1.layer_with_weights-1.layer_with_weights-6.beta\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).transformer.layer_with_weights-1.layer_with_weights-2.layer_with_weights-1.gamma\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).transformer.layer_with_weights-1.layer_with_weights-2.layer_with_weights-1.beta\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).transformer.layer_with_weights-1.layer_with_weights-2.layer_with_weights-3.gamma\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).transformer.layer_with_weights-1.layer_with_weights-2.layer_with_weights-3.beta\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).transformer.layer_with_weights-1.layer_with_weights-2.layer_with_weights-4.kernel\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).transformer.layer_with_weights-1.layer_with_weights-2.layer_with_weights-4.bias\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).transformer.layer_with_weights-1.layer_with_weights-2.layer_with_weights-5.kernel\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).transformer.layer_with_weights-1.layer_with_weights-2.layer_with_weights-5.bias\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).transformer.layer_with_weights-1.layer_with_weights-2.layer_with_weights-6.gamma\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).transformer.layer_with_weights-1.layer_with_weights-2.layer_with_weights-6.beta\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).transformer.layer_with_weights-0.layer_with_weights-1.layer_with_weights-0.wq.kernel\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).transformer.layer_with_weights-0.layer_with_weights-1.layer_with_weights-0.wq.bias\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).transformer.layer_with_weights-0.layer_with_weights-1.layer_with_weights-0.wk.kernel\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).transformer.layer_with_weights-0.layer_with_weights-1.layer_with_weights-0.wk.bias\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).transformer.layer_with_weights-0.layer_with_weights-1.layer_with_weights-0.wv.kernel\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).transformer.layer_with_weights-0.layer_with_weights-1.layer_with_weights-0.wv.bias\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).transformer.layer_with_weights-0.layer_with_weights-1.layer_with_weights-0.dense.kernel\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).transformer.layer_with_weights-0.layer_with_weights-1.layer_with_weights-0.dense.bias\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).transformer.layer_with_weights-0.layer_with_weights-2.layer_with_weights-0.wq.kernel\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).transformer.layer_with_weights-0.layer_with_weights-2.layer_with_weights-0.wq.bias\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).transformer.layer_with_weights-0.layer_with_weights-2.layer_with_weights-0.wk.kernel\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).transformer.layer_with_weights-0.layer_with_weights-2.layer_with_weights-0.wk.bias\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).transformer.layer_with_weights-0.layer_with_weights-2.layer_with_weights-0.wv.kernel\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).transformer.layer_with_weights-0.layer_with_weights-2.layer_with_weights-0.wv.bias\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).transformer.layer_with_weights-0.layer_with_weights-2.layer_with_weights-0.dense.kernel\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).transformer.layer_with_weights-0.layer_with_weights-2.layer_with_weights-0.dense.bias\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).transformer.layer_with_weights-1.layer_with_weights-1.layer_with_weights-0.wq.kernel\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).transformer.layer_with_weights-1.layer_with_weights-1.layer_with_weights-0.wq.bias\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).transformer.layer_with_weights-1.layer_with_weights-1.layer_with_weights-0.wk.kernel\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).transformer.layer_with_weights-1.layer_with_weights-1.layer_with_weights-0.wk.bias\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).transformer.layer_with_weights-1.layer_with_weights-1.layer_with_weights-0.wv.kernel\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).transformer.layer_with_weights-1.layer_with_weights-1.layer_with_weights-0.wv.bias\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).transformer.layer_with_weights-1.layer_with_weights-1.layer_with_weights-0.dense.kernel\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).transformer.layer_with_weights-1.layer_with_weights-1.layer_with_weights-0.dense.bias\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).transformer.layer_with_weights-1.layer_with_weights-1.layer_with_weights-2.wq.kernel\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).transformer.layer_with_weights-1.layer_with_weights-1.layer_with_weights-2.wq.bias\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).transformer.layer_with_weights-1.layer_with_weights-1.layer_with_weights-2.wk.kernel\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).transformer.layer_with_weights-1.layer_with_weights-1.layer_with_weights-2.wk.bias\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).transformer.layer_with_weights-1.layer_with_weights-1.layer_with_weights-2.wv.kernel\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).transformer.layer_with_weights-1.layer_with_weights-1.layer_with_weights-2.wv.bias\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).transformer.layer_with_weights-1.layer_with_weights-1.layer_with_weights-2.dense.kernel\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).transformer.layer_with_weights-1.layer_with_weights-1.layer_with_weights-2.dense.bias\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).transformer.layer_with_weights-1.layer_with_weights-2.layer_with_weights-0.wq.kernel\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).transformer.layer_with_weights-1.layer_with_weights-2.layer_with_weights-0.wq.bias\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).transformer.layer_with_weights-1.layer_with_weights-2.layer_with_weights-0.wk.kernel\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).transformer.layer_with_weights-1.layer_with_weights-2.layer_with_weights-0.wk.bias\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).transformer.layer_with_weights-1.layer_with_weights-2.layer_with_weights-0.wv.kernel\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).transformer.layer_with_weights-1.layer_with_weights-2.layer_with_weights-0.wv.bias\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).transformer.layer_with_weights-1.layer_with_weights-2.layer_with_weights-0.dense.kernel\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).transformer.layer_with_weights-1.layer_with_weights-2.layer_with_weights-0.dense.bias\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).transformer.layer_with_weights-1.layer_with_weights-2.layer_with_weights-2.wq.kernel\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).transformer.layer_with_weights-1.layer_with_weights-2.layer_with_weights-2.wq.bias\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).transformer.layer_with_weights-1.layer_with_weights-2.layer_with_weights-2.wk.kernel\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).transformer.layer_with_weights-1.layer_with_weights-2.layer_with_weights-2.wk.bias\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).transformer.layer_with_weights-1.layer_with_weights-2.layer_with_weights-2.wv.kernel\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).transformer.layer_with_weights-1.layer_with_weights-2.layer_with_weights-2.wv.bias\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).transformer.layer_with_weights-1.layer_with_weights-2.layer_with_weights-2.dense.kernel\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).transformer.layer_with_weights-1.layer_with_weights-2.layer_with_weights-2.dense.bias\n",
      "WARNING:tensorflow:Detecting that an object or model or tf.train.Checkpoint is being deleted with unrestored values. See the following logs for the specific values in question. To silence these warnings, use `status.expect_partial()`. See https://www.tensorflow.org/api_docs/python/tf/train/Checkpoint#restorefor details about the status object returned by the restore function.\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).transformer.layer_with_weights-2.kernel\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).transformer.layer_with_weights-2.bias\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).transformer.layer_with_weights-0.layer_with_weights-0.embeddings\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).transformer.layer_with_weights-1.layer_with_weights-0.embeddings\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).transformer.layer_with_weights-0.layer_with_weights-1.layer_with_weights-1.gamma\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).transformer.layer_with_weights-0.layer_with_weights-1.layer_with_weights-1.beta\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).transformer.layer_with_weights-0.layer_with_weights-1.layer_with_weights-2.kernel\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).transformer.layer_with_weights-0.layer_with_weights-1.layer_with_weights-2.bias\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).transformer.layer_with_weights-0.layer_with_weights-1.layer_with_weights-3.kernel\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).transformer.layer_with_weights-0.layer_with_weights-1.layer_with_weights-3.bias\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).transformer.layer_with_weights-0.layer_with_weights-1.layer_with_weights-4.gamma\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).transformer.layer_with_weights-0.layer_with_weights-1.layer_with_weights-4.beta\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).transformer.layer_with_weights-0.layer_with_weights-2.layer_with_weights-1.gamma\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).transformer.layer_with_weights-0.layer_with_weights-2.layer_with_weights-1.beta\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).transformer.layer_with_weights-0.layer_with_weights-2.layer_with_weights-2.kernel\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).transformer.layer_with_weights-0.layer_with_weights-2.layer_with_weights-2.bias\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).transformer.layer_with_weights-0.layer_with_weights-2.layer_with_weights-3.kernel\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).transformer.layer_with_weights-0.layer_with_weights-2.layer_with_weights-3.bias\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).transformer.layer_with_weights-0.layer_with_weights-2.layer_with_weights-4.gamma\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).transformer.layer_with_weights-0.layer_with_weights-2.layer_with_weights-4.beta\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).transformer.layer_with_weights-1.layer_with_weights-1.layer_with_weights-1.gamma\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).transformer.layer_with_weights-1.layer_with_weights-1.layer_with_weights-1.beta\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).transformer.layer_with_weights-1.layer_with_weights-1.layer_with_weights-3.gamma\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).transformer.layer_with_weights-1.layer_with_weights-1.layer_with_weights-3.beta\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).transformer.layer_with_weights-1.layer_with_weights-1.layer_with_weights-4.kernel\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).transformer.layer_with_weights-1.layer_with_weights-1.layer_with_weights-4.bias\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).transformer.layer_with_weights-1.layer_with_weights-1.layer_with_weights-5.kernel\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).transformer.layer_with_weights-1.layer_with_weights-1.layer_with_weights-5.bias\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).transformer.layer_with_weights-1.layer_with_weights-1.layer_with_weights-6.gamma\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).transformer.layer_with_weights-1.layer_with_weights-1.layer_with_weights-6.beta\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).transformer.layer_with_weights-1.layer_with_weights-2.layer_with_weights-1.gamma\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).transformer.layer_with_weights-1.layer_with_weights-2.layer_with_weights-1.beta\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).transformer.layer_with_weights-1.layer_with_weights-2.layer_with_weights-3.gamma\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).transformer.layer_with_weights-1.layer_with_weights-2.layer_with_weights-3.beta\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).transformer.layer_with_weights-1.layer_with_weights-2.layer_with_weights-4.kernel\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).transformer.layer_with_weights-1.layer_with_weights-2.layer_with_weights-4.bias\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).transformer.layer_with_weights-1.layer_with_weights-2.layer_with_weights-5.kernel\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).transformer.layer_with_weights-1.layer_with_weights-2.layer_with_weights-5.bias\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).transformer.layer_with_weights-1.layer_with_weights-2.layer_with_weights-6.gamma\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).transformer.layer_with_weights-1.layer_with_weights-2.layer_with_weights-6.beta\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).transformer.layer_with_weights-0.layer_with_weights-1.layer_with_weights-0.wq.kernel\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).transformer.layer_with_weights-0.layer_with_weights-1.layer_with_weights-0.wq.bias\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).transformer.layer_with_weights-0.layer_with_weights-1.layer_with_weights-0.wk.kernel\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).transformer.layer_with_weights-0.layer_with_weights-1.layer_with_weights-0.wk.bias\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).transformer.layer_with_weights-0.layer_with_weights-1.layer_with_weights-0.wv.kernel\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).transformer.layer_with_weights-0.layer_with_weights-1.layer_with_weights-0.wv.bias\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).transformer.layer_with_weights-0.layer_with_weights-1.layer_with_weights-0.dense.kernel\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).transformer.layer_with_weights-0.layer_with_weights-1.layer_with_weights-0.dense.bias\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).transformer.layer_with_weights-0.layer_with_weights-2.layer_with_weights-0.wq.kernel\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).transformer.layer_with_weights-0.layer_with_weights-2.layer_with_weights-0.wq.bias\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).transformer.layer_with_weights-0.layer_with_weights-2.layer_with_weights-0.wk.kernel\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).transformer.layer_with_weights-0.layer_with_weights-2.layer_with_weights-0.wk.bias\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).transformer.layer_with_weights-0.layer_with_weights-2.layer_with_weights-0.wv.kernel\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).transformer.layer_with_weights-0.layer_with_weights-2.layer_with_weights-0.wv.bias\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).transformer.layer_with_weights-0.layer_with_weights-2.layer_with_weights-0.dense.kernel\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).transformer.layer_with_weights-0.layer_with_weights-2.layer_with_weights-0.dense.bias\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).transformer.layer_with_weights-1.layer_with_weights-1.layer_with_weights-0.wq.kernel\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).transformer.layer_with_weights-1.layer_with_weights-1.layer_with_weights-0.wq.bias\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).transformer.layer_with_weights-1.layer_with_weights-1.layer_with_weights-0.wk.kernel\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).transformer.layer_with_weights-1.layer_with_weights-1.layer_with_weights-0.wk.bias\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).transformer.layer_with_weights-1.layer_with_weights-1.layer_with_weights-0.wv.kernel\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).transformer.layer_with_weights-1.layer_with_weights-1.layer_with_weights-0.wv.bias\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).transformer.layer_with_weights-1.layer_with_weights-1.layer_with_weights-0.dense.kernel\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).transformer.layer_with_weights-1.layer_with_weights-1.layer_with_weights-0.dense.bias\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).transformer.layer_with_weights-1.layer_with_weights-1.layer_with_weights-2.wq.kernel\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).transformer.layer_with_weights-1.layer_with_weights-1.layer_with_weights-2.wq.bias\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).transformer.layer_with_weights-1.layer_with_weights-1.layer_with_weights-2.wk.kernel\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).transformer.layer_with_weights-1.layer_with_weights-1.layer_with_weights-2.wk.bias\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).transformer.layer_with_weights-1.layer_with_weights-1.layer_with_weights-2.wv.kernel\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).transformer.layer_with_weights-1.layer_with_weights-1.layer_with_weights-2.wv.bias\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).transformer.layer_with_weights-1.layer_with_weights-1.layer_with_weights-2.dense.kernel\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).transformer.layer_with_weights-1.layer_with_weights-1.layer_with_weights-2.dense.bias\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).transformer.layer_with_weights-1.layer_with_weights-2.layer_with_weights-0.wq.kernel\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).transformer.layer_with_weights-1.layer_with_weights-2.layer_with_weights-0.wq.bias\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).transformer.layer_with_weights-1.layer_with_weights-2.layer_with_weights-0.wk.kernel\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).transformer.layer_with_weights-1.layer_with_weights-2.layer_with_weights-0.wk.bias\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).transformer.layer_with_weights-1.layer_with_weights-2.layer_with_weights-0.wv.kernel\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).transformer.layer_with_weights-1.layer_with_weights-2.layer_with_weights-0.wv.bias\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).transformer.layer_with_weights-1.layer_with_weights-2.layer_with_weights-0.dense.kernel\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).transformer.layer_with_weights-1.layer_with_weights-2.layer_with_weights-0.dense.bias\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).transformer.layer_with_weights-1.layer_with_weights-2.layer_with_weights-2.wq.kernel\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).transformer.layer_with_weights-1.layer_with_weights-2.layer_with_weights-2.wq.bias\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).transformer.layer_with_weights-1.layer_with_weights-2.layer_with_weights-2.wk.kernel\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).transformer.layer_with_weights-1.layer_with_weights-2.layer_with_weights-2.wk.bias\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).transformer.layer_with_weights-1.layer_with_weights-2.layer_with_weights-2.wv.kernel\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).transformer.layer_with_weights-1.layer_with_weights-2.layer_with_weights-2.wv.bias\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).transformer.layer_with_weights-1.layer_with_weights-2.layer_with_weights-2.dense.kernel\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).transformer.layer_with_weights-1.layer_with_weights-2.layer_with_weights-2.dense.bias\n",
      "Época 1/5\n",
      "  Época 1: Train Loss 7.6899, Val Loss 6.5080\n",
      "  Tiempo: 25.99s\n",
      "\n",
      "Época 2/5\n",
      "  Época 2: Train Loss 6.2583, Val Loss 6.2687\n",
      "  Tiempo: 19.10s\n",
      "\n",
      "Época 3/5\n",
      "  Época 3: Train Loss 6.1029, Val Loss 6.0978\n",
      "  Tiempo: 18.49s\n",
      "\n",
      "Época 4/5\n",
      "  Época 4: Train Loss 5.8561, Val Loss 5.9023\n",
      "  Tiempo: 19.02s\n",
      "\n",
      "Época 5/5\n",
      "  Época 5: Train Loss 5.5875, Val Loss 5.7692\n",
      "  Tiempo: 19.74s\n",
      "\n",
      "\n",
      "=== ENTRENAMIENTO COMPLETADO ===\n",
      "\n",
      "\n",
      "Generando texto a partir de: 'En un lugar de la'\n",
      "Texto generado: 'en un lugar de la <UNK> de la <UNK> de la <UNK> ponérselas'\n"
     ]
    }
   ],
   "source": [
    "# Entrenar el modelo\n",
    "import gc\n",
    "train_model(EPOCHS)\n",
    "\n",
    "# Generar texto de ejemplo\n",
    "print(\"\\nGenerando texto a partir de: 'En un lugar de la'\")\n",
    "generated_text = generate_text(transformer, tokenizer, 'En un lugar de la', max_length=50, temperature=0.7)\n",
    "print(f'Texto generado: \\'{generated_text}\\'')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "64704f8c-1744-48f9-b9b8-a3f47f52d28e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text(prompt, max_length=50, temperature=1.0, num_samples=1, top_k=0):\n",
    "    \"\"\"\n",
    "    Generate text using the trained Transformer model with various customization options.\n",
    "    \n",
    "    Args:\n",
    "        prompt (str): The input text prompt to start generation\n",
    "        max_length (int): Maximum length of generated sequence\n",
    "        temperature (float): Controls randomness in sampling. Higher values (e.g. 1.0) make output more random, \n",
    "                            lower values (e.g. 0.2) make it more deterministic\n",
    "        num_samples (int): Number of different text samples to generate\n",
    "        top_k (int): If > 0, use top-k sampling (keeping only top k tokens with highest probability)\n",
    "        \n",
    "    Returns:\n",
    "        List of generated text samples\n",
    "    \"\"\"\n",
    "    # Encode the input prompt\n",
    "    encoder_input = tf.expand_dims(tokenizer.texts_to_sequences([prompt])[0], 0)\n",
    "    \n",
    "    # Initialize with start token\n",
    "    decoder_input = tf.expand_dims([tokenizer_target.word_index['<start>']], 0)\n",
    "    \n",
    "    results = []\n",
    "    \n",
    "    for _ in range(num_samples):\n",
    "        output = decoder_input\n",
    "        \n",
    "        # Generate text token by token\n",
    "        for i in range(max_length):\n",
    "            # Get predictions\n",
    "            predictions = transformer([encoder_input, output], training=False)\n",
    "            \n",
    "            # Focus on the last token's prediction\n",
    "            predictions = predictions[:, -1:, :]\n",
    "            \n",
    "            if temperature != 1.0:\n",
    "                # Apply temperature scaling\n",
    "                predictions = predictions / temperature\n",
    "                \n",
    "            if top_k > 0:\n",
    "                # Apply top-k sampling\n",
    "                top_k_predictions, top_k_indices = tf.nn.top_k(predictions[0, 0], k=top_k)\n",
    "                # Sample from top-k tokens\n",
    "                sampled_index = tf.random.categorical(tf.math.log([top_k_predictions]), num_samples=1)\n",
    "                predicted_id = top_k_indices[sampled_index[0][0]]\n",
    "            else:\n",
    "                # Sample from the distribution\n",
    "                predicted_id = tf.random.categorical(predictions[0], num_samples=1)[0, 0]\n",
    "            \n",
    "            # If end token, stop generation\n",
    "            if predicted_id == tokenizer_target.word_index.get('<end>', 1):\n",
    "                break\n",
    "                \n",
    "            # Concatenate predicted id to output\n",
    "            output = tf.concat([output, tf.expand_dims([predicted_id], 0)], axis=-1)\n",
    "        \n",
    "        # Decode the output sequence\n",
    "        output_text = tokenizer_target.sequences_to_texts(output.numpy())[0]\n",
    "        \n",
    "        # Clean up the output text\n",
    "        output_text = output_text.replace('<start>', '').replace('<end>', '')\n",
    "        output_text = prompt + output_text\n",
    "        \n",
    "        results.append(output_text)\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Example usage\n",
    "def test_model():\n",
    "    \"\"\"\n",
    "    Test the model with different prompts and parameters\n",
    "    \"\"\"\n",
    "    print(\"\\n=== PRUEBA DEL MODELO TRANSFORMER ===\\n\")\n",
    "    \n",
    "    prompts = [\n",
    "        \"En un lugar de la\",\n",
    "        \"La vida es\",\n",
    "        \"El tiempo\",\n",
    "        \"Cuando era joven\",\n",
    "        \"La noche estrellada\"\n",
    "    ]\n",
    "    \n",
    "    print(\"1. Generación básica (default settings):\")\n",
    "    for prompt in prompts:\n",
    "        results = generate_text(prompt)\n",
    "        print(f\"  Prompt: '{prompt}'\")\n",
    "        print(f\"  Output: '{results[0]}'\")\n",
    "    \n",
    "    print(\"\\n2. Generación con temperatura baja (más determinística):\")\n",
    "    results = generate_text(\"En un lugar de la\", temperature=0.5, num_samples=3)\n",
    "    for i, text in enumerate(results):\n",
    "        print(f\"  Sample {i+1}: '{text}'\")\n",
    "    \n",
    "    print(\"\\n3. Generación con temperatura alta (más creativa):\")\n",
    "    results = generate_text(\"En un lugar de la\", temperature=1.2, num_samples=3)\n",
    "    for i, text in enumerate(results):\n",
    "        print(f\"  Sample {i+1}: '{text}'\")\n",
    "    \n",
    "    print(\"\\n4. Generación con top-k sampling (k=5):\")\n",
    "    results = generate_text(\"En un lugar de la\", top_k=5, num_samples=3)\n",
    "    for i, text in enumerate(results):\n",
    "        print(f\"  Sample {i+1}: '{text}'\")\n",
    "    \n",
    "    print(\"\\n5. Generación de texto más largo:\")\n",
    "    results = generate_text(\"En un lugar de la\", max_length=100)\n",
    "    print(f\"  Output: '{results[0]}'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d94685c",
   "metadata": {},
   "source": [
    "# Comparación entre arquitecturas: Transformer vs LSTM\n",
    "\n",
    "## Diferencias arquitectónicas clave\n",
    "\n",
    "| Característica | Transformer | LSTM |\n",
    "|----------------|-------------|------|\n",
    "| **Procesamiento** | Paralelo (procesa toda la secuencia a la vez) | Secuencial (procesa token por token) |\n",
    "| **Mecanismo de atención** | Multi-head attention (global) | Gates y celdas de memoria (local) |\n",
    "| **Dependencias a largo plazo** | Captura directamente mediante auto-atención | Limitado por el \"vanishing gradient\" |\n",
    "| **Complejidad computacional** | O(n²) por la auto-atención | O(n) pero no paralelizable |\n",
    "| **Paralelización** | Altamente paralelizable | Inherentemente secuencial |\n",
    "| **Cantidad de parámetros** | Mayor | Menor |\n",
    "\n",
    "## Ventajas del Transformer sobre LSTM\n",
    "\n",
    "1. **Captura dependencias a larga distancia**: La auto-atención permite al Transformer relacionar palabras separadas por grandes distancias en el texto sin degradación.\n",
    "   \n",
    "2. **Entrenamiento más rápido**: Gracias a la paralelización, los Transformers pueden entrenar mucho más rápido, especialmente con hardware especializado como GPUs.\n",
    "\n",
    "3. **Mejor rendimiento en secuencias largas**: La arquitectura de atención maneja mejor textos extensos sin perder información contextual.\n",
    "\n",
    "4. **Escalabilidad**: Los Transformers se escalan mejor con más datos y parámetros, como demuestran modelos como GPT y BERT.\n",
    "\n",
    "## Comparación de rendimiento\n",
    "\n",
    "Nuestros experimentos muestran:\n",
    "\n",
    "- **Precisión**: El modelo Transformer alcanzó aproximadamente 5-8% mejor precisión que el"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
