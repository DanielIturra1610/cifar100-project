{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "83c1fa8a",
   "metadata": {},
   "source": [
    "# Transfer Learning con Inception-Style CNN ‚Äì CIFAR-100\n",
    "\n",
    "### En este notebook construiremos un modelo convolucional basado en Inception Blocks para clasificar im√°genes del dataset CIFAR-100 usando sus 20 superclases."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed83fc9b",
   "metadata": {},
   "source": [
    "## üß† Importar librer√≠as necesarias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4c08a2a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-19 03:37:15.052003: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-04-19 03:37:15.121234: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2025-04-19 03:37:15.121280: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2025-04-19 03:37:15.123980: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-04-19 03:37:15.136349: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-04-19 03:37:15.138164: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-04-19 03:37:16.893430: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.datasets import cifar100\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras import layers, models, regularizers\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efb357b1",
   "metadata": {},
   "source": [
    "## üì¶ Cargar y preparar los datos\n",
    "Cargar im√°genes y etiquetas de CIFAR-100, usando superclases (20 clases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fc83667d",
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = cifar100.load_data(label_mode='coarse')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f28f47f",
   "metadata": {},
   "source": [
    "Normalizaci√≥n de im√°genes: valores de p√≠xeles a rango [0,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "437e7bb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train.astype('float32') / 255.0\n",
    "x_test = x_test.astype('float32') / 255.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d8656ba",
   "metadata": {},
   "source": [
    "Conversi√≥n de etiquetas a codificaci√≥n one-hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8cc9079e",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_cat = to_categorical(y_train, 20)\n",
    "y_test_cat = to_categorical(y_test, 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd87791c",
   "metadata": {},
   "source": [
    "## üî• Aumentaci√≥n de datos\n",
    "Crear generador de im√°genes con transformaciones aleatorias para robustecer el entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0fad6686",
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.1,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    validation_split=0.2\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ba16755",
   "metadata": {},
   "source": [
    "Crear generadores para entrenamiento y validaci√≥n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b7d757d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_generator = datagen.flow(x_train, y_train_cat, batch_size=32, subset='training')\n",
    "val_generator = datagen.flow(x_train, y_train_cat, batch_size=32, subset='validation')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc216b2b",
   "metadata": {},
   "source": [
    "## üß± Definici√≥n de la Arquitectura CNN con Inception Blocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1b41a148",
   "metadata": {},
   "outputs": [],
   "source": [
    "def inception_block(x, filters):\n",
    "    f1, f3, f5 = filters\n",
    "\n",
    "    path1 = layers.Conv2D(f1, (1, 1), padding='same', kernel_regularizer=regularizers.l2(1e-4))(x)\n",
    "    path1 = layers.LeakyReLU(alpha=0.1)(path1)\n",
    "\n",
    "    path2 = layers.Conv2D(f3, (1, 1), padding='same', kernel_regularizer=regularizers.l2(1e-4))(x)\n",
    "    path2 = layers.LeakyReLU(alpha=0.1)(path2)\n",
    "    path2 = layers.Conv2D(f3, (3, 3), padding='same', kernel_regularizer=regularizers.l2(1e-4))(path2)\n",
    "    path2 = layers.LeakyReLU(alpha=0.1)(path2)\n",
    "\n",
    "    path3 = layers.Conv2D(f5, (1, 1), padding='same', kernel_regularizer=regularizers.l2(1e-4))(x)\n",
    "    path3 = layers.LeakyReLU(alpha=0.1)(path3)\n",
    "    path3 = layers.Conv2D(f5, (5, 5), padding='same', kernel_regularizer=regularizers.l2(1e-4))(path3)\n",
    "    path3 = layers.LeakyReLU(alpha=0.1)(path3)\n",
    "\n",
    "    path4 = layers.MaxPooling2D((3, 3), strides=(1, 1), padding='same')(x)\n",
    "    path4 = layers.Conv2D(f1, (1, 1), padding='same', kernel_regularizer=regularizers.l2(1e-4))(path4)\n",
    "    path4 = layers.LeakyReLU(alpha=0.1)(path4)\n",
    "\n",
    "    return layers.concatenate([path1, path2, path3, path4], axis=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d1034d8",
   "metadata": {},
   "source": [
    "## ‚öôÔ∏è Construcci√≥n del modelo CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2c5daeea",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_layer = layers.Input(shape=(32, 32, 3))\n",
    "\n",
    "x = layers.Conv2D(32, (3, 3), padding='same', kernel_regularizer=regularizers.l2(1e-4))(input_layer)\n",
    "x = layers.LeakyReLU(alpha=0.1)(x)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.Conv2D(32, (3, 3), kernel_regularizer=regularizers.l2(1e-4))(x)\n",
    "x = layers.LeakyReLU(alpha=0.1)(x)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.MaxPooling2D((2, 2))(x)\n",
    "x = layers.Dropout(0.25)(x)\n",
    "\n",
    "x = inception_block(x, filters=(64, 96, 128))\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.MaxPooling2D((2, 2))(x)\n",
    "x = layers.Dropout(0.3)(x)\n",
    "\n",
    "x = inception_block(x, filters=(64, 96, 128))\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.MaxPooling2D((2, 2))(x)\n",
    "x = layers.Dropout(0.3)(x)\n",
    "\n",
    "x = layers.Conv2D(64, (3, 3), padding='same', kernel_regularizer=regularizers.l2(1e-4))(x)\n",
    "x = layers.LeakyReLU(alpha=0.1)(x)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.MaxPooling2D((2, 2))(x)\n",
    "x = layers.Dropout(0.4)(x)\n",
    "\n",
    "x = layers.GlobalAveragePooling2D()(x)\n",
    "x = layers.Dense(256, kernel_regularizer=regularizers.l2(1e-4))(x)\n",
    "x = layers.LeakyReLU(alpha=0.1)(x)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.Dropout(0.5)(x)\n",
    "\n",
    "output = layers.Dense(20, activation='softmax')(x)\n",
    "\n",
    "model = models.Model(inputs=input_layer, outputs=output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e4d05bd",
   "metadata": {},
   "source": [
    "## ‚ö° Compilaci√≥n del modelo\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "666b9741",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = SGD(learning_rate=1e-2, momentum=0.9, nesterov=True)\n",
    "model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7464f37",
   "metadata": {},
   "source": [
    "## üíæ Callbacks para entrenamiento\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "615031ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stop = EarlyStopping(monitor='val_accuracy', patience=5, restore_best_weights=True, verbose=1)\n",
    "checkpoint_cb = ModelCheckpoint(filepath='checkpoints/cnn_cifar100_superclass_best.h5', monitor='val_accuracy', save_best_only=True, verbose=1)\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_accuracy', factor=0.5, patience=3, verbose=1, min_lr=1e-6)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae259ed2",
   "metadata": {},
   "source": [
    "## üöÄ Entrenamiento del modelo\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "27cc2369",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "1250/1250 [==============================] - ETA: 0s - loss: 3.1244 - accuracy: 0.1380\n",
      "Epoch 1: val_accuracy improved from -inf to 0.15640, saving model to checkpoints/cnn_cifar100_superclass_best.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/site-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1250/1250 [==============================] - 214s 169ms/step - loss: 3.1244 - accuracy: 0.1380 - val_loss: 2.8929 - val_accuracy: 0.1564 - lr: 0.0100\n",
      "Epoch 2/50\n",
      "1250/1250 [==============================] - ETA: 0s - loss: 2.7596 - accuracy: 0.1968\n",
      "Epoch 2: val_accuracy improved from 0.15640 to 0.16960, saving model to checkpoints/cnn_cifar100_superclass_best.h5\n",
      "1250/1250 [==============================] - 247s 198ms/step - loss: 2.7596 - accuracy: 0.1968 - val_loss: 2.8656 - val_accuracy: 0.1696 - lr: 0.0100\n",
      "Epoch 3/50\n",
      "1250/1250 [==============================] - ETA: 0s - loss: 2.5940 - accuracy: 0.2416\n",
      "Epoch 3: val_accuracy improved from 0.16960 to 0.22830, saving model to checkpoints/cnn_cifar100_superclass_best.h5\n",
      "1250/1250 [==============================] - 186s 149ms/step - loss: 2.5940 - accuracy: 0.2416 - val_loss: 2.6192 - val_accuracy: 0.2283 - lr: 0.0100\n",
      "Epoch 4/50\n",
      "1250/1250 [==============================] - ETA: 0s - loss: 2.4918 - accuracy: 0.2712\n",
      "Epoch 4: val_accuracy improved from 0.22830 to 0.25930, saving model to checkpoints/cnn_cifar100_superclass_best.h5\n",
      "1250/1250 [==============================] - 190s 152ms/step - loss: 2.4918 - accuracy: 0.2712 - val_loss: 2.5587 - val_accuracy: 0.2593 - lr: 0.0100\n",
      "Epoch 5/50\n",
      "1250/1250 [==============================] - ETA: 0s - loss: 2.4133 - accuracy: 0.2982\n",
      "Epoch 5: val_accuracy improved from 0.25930 to 0.27150, saving model to checkpoints/cnn_cifar100_superclass_best.h5\n",
      "1250/1250 [==============================] - 325s 260ms/step - loss: 2.4133 - accuracy: 0.2982 - val_loss: 2.4787 - val_accuracy: 0.2715 - lr: 0.0100\n",
      "Epoch 6/50\n",
      "1250/1250 [==============================] - ETA: 0s - loss: 2.3379 - accuracy: 0.3209\n",
      "Epoch 6: val_accuracy did not improve from 0.27150\n",
      "1250/1250 [==============================] - 223s 178ms/step - loss: 2.3379 - accuracy: 0.3209 - val_loss: 2.5837 - val_accuracy: 0.2638 - lr: 0.0100\n",
      "Epoch 7/50\n",
      "1250/1250 [==============================] - ETA: 0s - loss: 2.2799 - accuracy: 0.3419\n",
      "Epoch 7: val_accuracy improved from 0.27150 to 0.34090, saving model to checkpoints/cnn_cifar100_superclass_best.h5\n",
      "1250/1250 [==============================] - 216s 173ms/step - loss: 2.2799 - accuracy: 0.3419 - val_loss: 2.2725 - val_accuracy: 0.3409 - lr: 0.0100\n",
      "Epoch 8/50\n",
      "1250/1250 [==============================] - ETA: 0s - loss: 2.2251 - accuracy: 0.3555\n",
      "Epoch 8: val_accuracy did not improve from 0.34090\n",
      "1250/1250 [==============================] - 219s 176ms/step - loss: 2.2251 - accuracy: 0.3555 - val_loss: 2.5970 - val_accuracy: 0.2808 - lr: 0.0100\n",
      "Epoch 9/50\n",
      "1250/1250 [==============================] - ETA: 0s - loss: 2.1828 - accuracy: 0.3729\n",
      "Epoch 9: val_accuracy improved from 0.34090 to 0.37410, saving model to checkpoints/cnn_cifar100_superclass_best.h5\n",
      "1250/1250 [==============================] - 220s 176ms/step - loss: 2.1828 - accuracy: 0.3729 - val_loss: 2.1949 - val_accuracy: 0.3741 - lr: 0.0100\n",
      "Epoch 10/50\n",
      "1250/1250 [==============================] - ETA: 0s - loss: 2.1364 - accuracy: 0.3867\n",
      "Epoch 10: val_accuracy did not improve from 0.37410\n",
      "1250/1250 [==============================] - 213s 171ms/step - loss: 2.1364 - accuracy: 0.3867 - val_loss: 2.3872 - val_accuracy: 0.3187 - lr: 0.0100\n",
      "Epoch 11/50\n",
      "1250/1250 [==============================] - ETA: 0s - loss: 2.0981 - accuracy: 0.3995\n",
      "Epoch 11: val_accuracy improved from 0.37410 to 0.38790, saving model to checkpoints/cnn_cifar100_superclass_best.h5\n",
      "1250/1250 [==============================] - 213s 170ms/step - loss: 2.0981 - accuracy: 0.3995 - val_loss: 2.1787 - val_accuracy: 0.3879 - lr: 0.0100\n",
      "Epoch 12/50\n",
      "1250/1250 [==============================] - ETA: 0s - loss: 2.0690 - accuracy: 0.4094\n",
      "Epoch 12: val_accuracy improved from 0.38790 to 0.43240, saving model to checkpoints/cnn_cifar100_superclass_best.h5\n",
      "1250/1250 [==============================] - 214s 171ms/step - loss: 2.0690 - accuracy: 0.4094 - val_loss: 1.9956 - val_accuracy: 0.4324 - lr: 0.0100\n",
      "Epoch 13/50\n",
      "1250/1250 [==============================] - ETA: 0s - loss: 2.0326 - accuracy: 0.4229\n",
      "Epoch 13: val_accuracy did not improve from 0.43240\n",
      "1250/1250 [==============================] - 223s 178ms/step - loss: 2.0326 - accuracy: 0.4229 - val_loss: 2.1083 - val_accuracy: 0.4007 - lr: 0.0100\n",
      "Epoch 14/50\n",
      "1250/1250 [==============================] - ETA: 0s - loss: 2.0071 - accuracy: 0.4323\n",
      "Epoch 14: val_accuracy improved from 0.43240 to 0.45120, saving model to checkpoints/cnn_cifar100_superclass_best.h5\n",
      "1250/1250 [==============================] - 210s 168ms/step - loss: 2.0071 - accuracy: 0.4323 - val_loss: 1.9265 - val_accuracy: 0.4512 - lr: 0.0100\n",
      "Epoch 15/50\n",
      "1250/1250 [==============================] - ETA: 0s - loss: 1.9787 - accuracy: 0.4391\n",
      "Epoch 15: val_accuracy did not improve from 0.45120\n",
      "1250/1250 [==============================] - 210s 168ms/step - loss: 1.9787 - accuracy: 0.4391 - val_loss: 2.1918 - val_accuracy: 0.3907 - lr: 0.0100\n",
      "Epoch 16/50\n",
      "1250/1250 [==============================] - ETA: 0s - loss: 1.9595 - accuracy: 0.4479\n",
      "Epoch 16: val_accuracy did not improve from 0.45120\n",
      "1250/1250 [==============================] - 213s 171ms/step - loss: 1.9595 - accuracy: 0.4479 - val_loss: 2.0162 - val_accuracy: 0.4375 - lr: 0.0100\n",
      "Epoch 17/50\n",
      "1250/1250 [==============================] - ETA: 0s - loss: 1.9275 - accuracy: 0.4570\n",
      "Epoch 17: val_accuracy did not improve from 0.45120\n",
      "\n",
      "Epoch 17: ReduceLROnPlateau reducing learning rate to 0.004999999888241291.\n",
      "1250/1250 [==============================] - 209s 167ms/step - loss: 1.9275 - accuracy: 0.4570 - val_loss: 1.9357 - val_accuracy: 0.4478 - lr: 0.0100\n",
      "Epoch 18/50\n",
      "1250/1250 [==============================] - ETA: 0s - loss: 1.8603 - accuracy: 0.4767\n",
      "Epoch 18: val_accuracy improved from 0.45120 to 0.49490, saving model to checkpoints/cnn_cifar100_superclass_best.h5\n",
      "1250/1250 [==============================] - 209s 168ms/step - loss: 1.8603 - accuracy: 0.4767 - val_loss: 1.7662 - val_accuracy: 0.4949 - lr: 0.0050\n",
      "Epoch 19/50\n",
      "1250/1250 [==============================] - ETA: 0s - loss: 1.8193 - accuracy: 0.4902\n",
      "Epoch 19: val_accuracy improved from 0.49490 to 0.49870, saving model to checkpoints/cnn_cifar100_superclass_best.h5\n",
      "1250/1250 [==============================] - 183s 147ms/step - loss: 1.8193 - accuracy: 0.4902 - val_loss: 1.7837 - val_accuracy: 0.4987 - lr: 0.0050\n",
      "Epoch 20/50\n",
      "1250/1250 [==============================] - ETA: 0s - loss: 1.7986 - accuracy: 0.4931\n",
      "Epoch 20: val_accuracy did not improve from 0.49870\n",
      "1250/1250 [==============================] - 181s 145ms/step - loss: 1.7986 - accuracy: 0.4931 - val_loss: 1.8587 - val_accuracy: 0.4721 - lr: 0.0050\n",
      "Epoch 21/50\n",
      "1250/1250 [==============================] - ETA: 0s - loss: 1.7887 - accuracy: 0.5016\n",
      "Epoch 21: val_accuracy did not improve from 0.49870\n",
      "1250/1250 [==============================] - 180s 144ms/step - loss: 1.7887 - accuracy: 0.5016 - val_loss: 1.7912 - val_accuracy: 0.4912 - lr: 0.0050\n",
      "Epoch 22/50\n",
      "1250/1250 [==============================] - ETA: 0s - loss: 1.7751 - accuracy: 0.5045\n",
      "Epoch 22: val_accuracy did not improve from 0.49870\n",
      "\n",
      "Epoch 22: ReduceLROnPlateau reducing learning rate to 0.0024999999441206455.\n",
      "1250/1250 [==============================] - 180s 144ms/step - loss: 1.7751 - accuracy: 0.5045 - val_loss: 1.8495 - val_accuracy: 0.4882 - lr: 0.0050\n",
      "Epoch 23/50\n",
      "1250/1250 [==============================] - ETA: 0s - loss: 1.7343 - accuracy: 0.5146\n",
      "Epoch 23: val_accuracy improved from 0.49870 to 0.52680, saving model to checkpoints/cnn_cifar100_superclass_best.h5\n",
      "1250/1250 [==============================] - 192s 154ms/step - loss: 1.7343 - accuracy: 0.5146 - val_loss: 1.6946 - val_accuracy: 0.5268 - lr: 0.0025\n",
      "Epoch 24/50\n",
      "1250/1250 [==============================] - ETA: 0s - loss: 1.7147 - accuracy: 0.5182\n",
      "Epoch 24: val_accuracy improved from 0.52680 to 0.54100, saving model to checkpoints/cnn_cifar100_superclass_best.h5\n",
      "1250/1250 [==============================] - 190s 152ms/step - loss: 1.7147 - accuracy: 0.5182 - val_loss: 1.6405 - val_accuracy: 0.5410 - lr: 0.0025\n",
      "Epoch 25/50\n",
      "1250/1250 [==============================] - ETA: 0s - loss: 1.6899 - accuracy: 0.5253\n",
      "Epoch 25: val_accuracy did not improve from 0.54100\n",
      "1250/1250 [==============================] - 197s 157ms/step - loss: 1.6899 - accuracy: 0.5253 - val_loss: 1.6795 - val_accuracy: 0.5359 - lr: 0.0025\n",
      "Epoch 26/50\n",
      "1250/1250 [==============================] - ETA: 0s - loss: 1.6802 - accuracy: 0.5287\n",
      "Epoch 26: val_accuracy improved from 0.54100 to 0.54530, saving model to checkpoints/cnn_cifar100_superclass_best.h5\n",
      "1250/1250 [==============================] - 205s 164ms/step - loss: 1.6802 - accuracy: 0.5287 - val_loss: 1.6489 - val_accuracy: 0.5453 - lr: 0.0025\n",
      "Epoch 27/50\n",
      "1250/1250 [==============================] - ETA: 0s - loss: 1.6745 - accuracy: 0.5303\n",
      "Epoch 27: val_accuracy did not improve from 0.54530\n",
      "1250/1250 [==============================] - 249s 199ms/step - loss: 1.6745 - accuracy: 0.5303 - val_loss: 1.6549 - val_accuracy: 0.5383 - lr: 0.0025\n",
      "Epoch 28/50\n",
      "1250/1250 [==============================] - ETA: 0s - loss: 1.6641 - accuracy: 0.5367\n",
      "Epoch 28: val_accuracy improved from 0.54530 to 0.54660, saving model to checkpoints/cnn_cifar100_superclass_best.h5\n",
      "1250/1250 [==============================] - 232s 185ms/step - loss: 1.6641 - accuracy: 0.5367 - val_loss: 1.6202 - val_accuracy: 0.5466 - lr: 0.0025\n",
      "Epoch 29/50\n",
      "1250/1250 [==============================] - ETA: 0s - loss: 1.6530 - accuracy: 0.5374\n",
      "Epoch 29: val_accuracy improved from 0.54660 to 0.55650, saving model to checkpoints/cnn_cifar100_superclass_best.h5\n",
      "1250/1250 [==============================] - 225s 180ms/step - loss: 1.6530 - accuracy: 0.5374 - val_loss: 1.5869 - val_accuracy: 0.5565 - lr: 0.0025\n",
      "Epoch 30/50\n",
      "1250/1250 [==============================] - ETA: 0s - loss: 1.6552 - accuracy: 0.5402\n",
      "Epoch 30: val_accuracy did not improve from 0.55650\n",
      "1250/1250 [==============================] - 214s 171ms/step - loss: 1.6552 - accuracy: 0.5402 - val_loss: 1.6261 - val_accuracy: 0.5458 - lr: 0.0025\n",
      "Epoch 31/50\n",
      "1250/1250 [==============================] - ETA: 0s - loss: 1.6433 - accuracy: 0.5379\n",
      "Epoch 31: val_accuracy did not improve from 0.55650\n",
      "1250/1250 [==============================] - 207s 165ms/step - loss: 1.6433 - accuracy: 0.5379 - val_loss: 1.6001 - val_accuracy: 0.5518 - lr: 0.0025\n",
      "Epoch 32/50\n",
      "1250/1250 [==============================] - ETA: 0s - loss: 1.6243 - accuracy: 0.5470\n",
      "Epoch 32: val_accuracy improved from 0.55650 to 0.56080, saving model to checkpoints/cnn_cifar100_superclass_best.h5\n",
      "1250/1250 [==============================] - 206s 165ms/step - loss: 1.6243 - accuracy: 0.5470 - val_loss: 1.5789 - val_accuracy: 0.5608 - lr: 0.0025\n",
      "Epoch 33/50\n",
      "1250/1250 [==============================] - ETA: 0s - loss: 1.6252 - accuracy: 0.5479\n",
      "Epoch 33: val_accuracy improved from 0.56080 to 0.57020, saving model to checkpoints/cnn_cifar100_superclass_best.h5\n",
      "1250/1250 [==============================] - 213s 170ms/step - loss: 1.6252 - accuracy: 0.5479 - val_loss: 1.5442 - val_accuracy: 0.5702 - lr: 0.0025\n",
      "Epoch 34/50\n",
      "1250/1250 [==============================] - ETA: 0s - loss: 1.6166 - accuracy: 0.5505\n",
      "Epoch 34: val_accuracy did not improve from 0.57020\n",
      "1250/1250 [==============================] - 210s 168ms/step - loss: 1.6166 - accuracy: 0.5505 - val_loss: 1.6808 - val_accuracy: 0.5360 - lr: 0.0025\n",
      "Epoch 35/50\n",
      "1250/1250 [==============================] - ETA: 0s - loss: 1.6158 - accuracy: 0.5490\n",
      "Epoch 35: val_accuracy did not improve from 0.57020\n",
      "1250/1250 [==============================] - 210s 168ms/step - loss: 1.6158 - accuracy: 0.5490 - val_loss: 1.5905 - val_accuracy: 0.5575 - lr: 0.0025\n",
      "Epoch 36/50\n",
      "1250/1250 [==============================] - ETA: 0s - loss: 1.6024 - accuracy: 0.5558\n",
      "Epoch 36: val_accuracy did not improve from 0.57020\n",
      "\n",
      "Epoch 36: ReduceLROnPlateau reducing learning rate to 0.0012499999720603228.\n",
      "1250/1250 [==============================] - 210s 168ms/step - loss: 1.6024 - accuracy: 0.5558 - val_loss: 1.5343 - val_accuracy: 0.5694 - lr: 0.0025\n",
      "Epoch 37/50\n",
      "1250/1250 [==============================] - ETA: 0s - loss: 1.5751 - accuracy: 0.5599\n",
      "Epoch 37: val_accuracy improved from 0.57020 to 0.58760, saving model to checkpoints/cnn_cifar100_superclass_best.h5\n",
      "1250/1250 [==============================] - 211s 169ms/step - loss: 1.5751 - accuracy: 0.5599 - val_loss: 1.4832 - val_accuracy: 0.5876 - lr: 0.0012\n",
      "Epoch 38/50\n",
      "1250/1250 [==============================] - ETA: 0s - loss: 1.5632 - accuracy: 0.5647\n",
      "Epoch 38: val_accuracy did not improve from 0.58760\n",
      "1250/1250 [==============================] - 210s 168ms/step - loss: 1.5632 - accuracy: 0.5647 - val_loss: 1.5578 - val_accuracy: 0.5724 - lr: 0.0012\n",
      "Epoch 39/50\n",
      "1250/1250 [==============================] - ETA: 0s - loss: 1.5503 - accuracy: 0.5691\n",
      "Epoch 39: val_accuracy did not improve from 0.58760\n",
      "1250/1250 [==============================] - 210s 168ms/step - loss: 1.5503 - accuracy: 0.5691 - val_loss: 1.5195 - val_accuracy: 0.5731 - lr: 0.0012\n",
      "Epoch 40/50\n",
      "1250/1250 [==============================] - ETA: 0s - loss: 1.5528 - accuracy: 0.5688\n",
      "Epoch 40: val_accuracy improved from 0.58760 to 0.59080, saving model to checkpoints/cnn_cifar100_superclass_best.h5\n",
      "1250/1250 [==============================] - 215s 172ms/step - loss: 1.5528 - accuracy: 0.5688 - val_loss: 1.4708 - val_accuracy: 0.5908 - lr: 0.0012\n",
      "Epoch 41/50\n",
      "1250/1250 [==============================] - ETA: 0s - loss: 1.5502 - accuracy: 0.5700\n",
      "Epoch 41: val_accuracy did not improve from 0.59080\n",
      "1250/1250 [==============================] - 215s 172ms/step - loss: 1.5502 - accuracy: 0.5700 - val_loss: 1.5414 - val_accuracy: 0.5695 - lr: 0.0012\n",
      "Epoch 42/50\n",
      "1250/1250 [==============================] - ETA: 0s - loss: 1.5355 - accuracy: 0.5757\n",
      "Epoch 42: val_accuracy did not improve from 0.59080\n",
      "1250/1250 [==============================] - 201s 161ms/step - loss: 1.5355 - accuracy: 0.5757 - val_loss: 1.4943 - val_accuracy: 0.5815 - lr: 0.0012\n",
      "Epoch 43/50\n",
      "1250/1250 [==============================] - ETA: 0s - loss: 1.5336 - accuracy: 0.5729\n",
      "Epoch 43: val_accuracy did not improve from 0.59080\n",
      "\n",
      "Epoch 43: ReduceLROnPlateau reducing learning rate to 0.0006249999860301614.\n",
      "1250/1250 [==============================] - 199s 159ms/step - loss: 1.5336 - accuracy: 0.5729 - val_loss: 1.5443 - val_accuracy: 0.5659 - lr: 0.0012\n",
      "Epoch 44/50\n",
      "1250/1250 [==============================] - ETA: 0s - loss: 1.5141 - accuracy: 0.5792\n",
      "Epoch 44: val_accuracy did not improve from 0.59080\n",
      "1250/1250 [==============================] - 199s 159ms/step - loss: 1.5141 - accuracy: 0.5792 - val_loss: 1.4728 - val_accuracy: 0.5823 - lr: 6.2500e-04\n",
      "Epoch 45/50\n",
      "1250/1250 [==============================] - ETA: 0s - loss: 1.5066 - accuracy: 0.5793Restoring model weights from the end of the best epoch: 40.\n",
      "\n",
      "Epoch 45: val_accuracy did not improve from 0.59080\n",
      "1250/1250 [==============================] - 197s 157ms/step - loss: 1.5066 - accuracy: 0.5793 - val_loss: 1.4770 - val_accuracy: 0.5900 - lr: 6.2500e-04\n",
      "Epoch 45: early stopping\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    train_generator,\n",
    "    epochs=50,\n",
    "    validation_data=val_generator,\n",
    "    callbacks=[early_stop, checkpoint_cb, reduce_lr],\n",
    "    verbose=1\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
