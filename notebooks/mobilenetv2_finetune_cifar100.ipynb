{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "99a477ac",
   "metadata": {},
   "source": [
    "# Fine-tuning MobileNetV2 on CIFAR-100\n",
    "This notebook continues training a MobileNetV2-based model that has reached ~69.2% validation accuracy, with the goal of pushing it past 70%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b8bc3c53",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-15 17:48:13.413984: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-04-15 17:48:13.458946: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2025-04-15 17:48:13.458988: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2025-04-15 17:48:13.460835: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-04-15 17:48:13.470332: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-04-15 17:48:13.471050: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-04-15 17:48:14.445551: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras import layers, models, optimizers, regularizers\n",
    "from tensorflow.keras.applications import MobileNetV2\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "import os\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8e83145",
   "metadata": {},
   "source": [
    "## Load previous best model and prepare dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "55d69ed3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load best model so far\n",
    "model = load_model('checkpoints/mobilenetv2_cifar100_best.h5')\n",
    "\n",
    "# Prepare data generators\n",
    "IMG_SIZE = 96\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.cifar100.load_data()\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    horizontal_flip=True,\n",
    "    zoom_range=0.2\n",
    ")\n",
    "\n",
    "train_gen = train_datagen.flow(x_train, tf.keras.utils.to_categorical(y_train, 100), batch_size=BATCH_SIZE)\n",
    "val_gen = ImageDataGenerator().flow(x_test, tf.keras.utils.to_categorical(y_test, 100), batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9924f1f6",
   "metadata": {},
   "source": [
    "## Fine-tuning the last 40 layers of MobileNetV2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cb9960cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encontrar la capa MobileNetV2 dentro del modelo\n",
    "base_model = None\n",
    "for layer in model.layers:\n",
    "    if isinstance(layer, tf.keras.Model) and layer.name.startswith('mobilenetv2'):\n",
    "        base_model = layer\n",
    "        break\n",
    "\n",
    "# Asegurarse de que encontramos MobileNetV2\n",
    "if base_model is not None:\n",
    "    base_model.trainable = True\n",
    "    # Congelar las primeras capas (ajustable)\n",
    "    for layer in base_model.layers[:-40]:\n",
    "        layer.trainable = False\n",
    "else:\n",
    "    raise ValueError(\"No se encontr√≥ MobileNetV2 en el modelo cargado.\")\n",
    "\n",
    "# Recompilar el modelo\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4),\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d038791",
   "metadata": {},
   "source": [
    "## Continue training with early stopping and learning rate scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "818e66ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "782/782 [==============================] - ETA: 0s - loss: 3.7149 - accuracy: 0.1350"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/site-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 [==============================] - 52s 61ms/step - loss: 3.7149 - accuracy: 0.1350 - val_loss: 2.8900 - val_accuracy: 0.2573 - lr: 1.0000e-04\n",
      "Epoch 2/30\n",
      "782/782 [==============================] - 44s 57ms/step - loss: 3.1959 - accuracy: 0.2189 - val_loss: 2.6103 - val_accuracy: 0.3251 - lr: 1.0000e-04\n",
      "Epoch 3/30\n",
      "782/782 [==============================] - 42s 54ms/step - loss: 2.9748 - accuracy: 0.2643 - val_loss: 2.5272 - val_accuracy: 0.3553 - lr: 1.0000e-04\n",
      "Epoch 4/30\n",
      "782/782 [==============================] - 44s 56ms/step - loss: 2.8516 - accuracy: 0.2936 - val_loss: 2.4160 - val_accuracy: 0.3752 - lr: 1.0000e-04\n",
      "Epoch 5/30\n",
      "782/782 [==============================] - 43s 54ms/step - loss: 2.7663 - accuracy: 0.3107 - val_loss: 2.3096 - val_accuracy: 0.3943 - lr: 1.0000e-04\n",
      "Epoch 6/30\n",
      "782/782 [==============================] - 45s 57ms/step - loss: 2.6792 - accuracy: 0.3300 - val_loss: 2.2852 - val_accuracy: 0.4026 - lr: 1.0000e-04\n",
      "Epoch 7/30\n",
      "782/782 [==============================] - 42s 54ms/step - loss: 2.6152 - accuracy: 0.3469 - val_loss: 2.3162 - val_accuracy: 0.4121 - lr: 1.0000e-04\n",
      "Epoch 8/30\n",
      "782/782 [==============================] - 45s 58ms/step - loss: 2.5584 - accuracy: 0.3556 - val_loss: 2.1941 - val_accuracy: 0.4251 - lr: 1.0000e-04\n",
      "Epoch 9/30\n",
      "782/782 [==============================] - 43s 55ms/step - loss: 2.4934 - accuracy: 0.3720 - val_loss: 2.1887 - val_accuracy: 0.4299 - lr: 1.0000e-04\n",
      "Epoch 10/30\n",
      "782/782 [==============================] - 45s 57ms/step - loss: 2.4498 - accuracy: 0.3802 - val_loss: 2.1576 - val_accuracy: 0.4351 - lr: 1.0000e-04\n",
      "Epoch 11/30\n",
      "782/782 [==============================] - 42s 54ms/step - loss: 2.4150 - accuracy: 0.3894 - val_loss: 2.1750 - val_accuracy: 0.4425 - lr: 1.0000e-04\n",
      "Epoch 12/30\n",
      "782/782 [==============================] - 43s 56ms/step - loss: 2.3658 - accuracy: 0.4047 - val_loss: 2.1440 - val_accuracy: 0.4437 - lr: 1.0000e-04\n",
      "Epoch 13/30\n",
      "782/782 [==============================] - 45s 58ms/step - loss: 2.3482 - accuracy: 0.4065 - val_loss: 2.1488 - val_accuracy: 0.4527 - lr: 1.0000e-04\n",
      "Epoch 14/30\n",
      "782/782 [==============================] - 44s 56ms/step - loss: 2.3053 - accuracy: 0.4136 - val_loss: 2.1463 - val_accuracy: 0.4463 - lr: 1.0000e-04\n",
      "Epoch 15/30\n",
      "782/782 [==============================] - 49s 63ms/step - loss: 2.2783 - accuracy: 0.4202 - val_loss: 2.1060 - val_accuracy: 0.4620 - lr: 1.0000e-04\n",
      "Epoch 16/30\n",
      "782/782 [==============================] - 48s 62ms/step - loss: 2.2433 - accuracy: 0.4290 - val_loss: 2.0858 - val_accuracy: 0.4623 - lr: 1.0000e-04\n",
      "Epoch 17/30\n",
      "782/782 [==============================] - 46s 58ms/step - loss: 2.2052 - accuracy: 0.4355 - val_loss: 2.0909 - val_accuracy: 0.4681 - lr: 1.0000e-04\n",
      "Epoch 18/30\n",
      "782/782 [==============================] - 48s 62ms/step - loss: 2.1779 - accuracy: 0.4433 - val_loss: 2.0422 - val_accuracy: 0.4737 - lr: 1.0000e-04\n",
      "Epoch 19/30\n",
      "782/782 [==============================] - 46s 59ms/step - loss: 2.1595 - accuracy: 0.4478 - val_loss: 2.1063 - val_accuracy: 0.4572 - lr: 1.0000e-04\n",
      "Epoch 20/30\n",
      "782/782 [==============================] - 46s 58ms/step - loss: 2.1269 - accuracy: 0.4548 - val_loss: 2.0548 - val_accuracy: 0.4728 - lr: 1.0000e-04\n",
      "Epoch 21/30\n",
      "782/782 [==============================] - 49s 62ms/step - loss: 2.1036 - accuracy: 0.4596 - val_loss: 2.0028 - val_accuracy: 0.4834 - lr: 1.0000e-04\n",
      "Epoch 22/30\n",
      "782/782 [==============================] - 47s 60ms/step - loss: 2.0812 - accuracy: 0.4647 - val_loss: 1.9671 - val_accuracy: 0.4866 - lr: 1.0000e-04\n",
      "Epoch 23/30\n",
      "782/782 [==============================] - 46s 59ms/step - loss: 2.0594 - accuracy: 0.4684 - val_loss: 2.0316 - val_accuracy: 0.4820 - lr: 1.0000e-04\n",
      "Epoch 24/30\n",
      "782/782 [==============================] - 47s 61ms/step - loss: 2.0403 - accuracy: 0.4739 - val_loss: 2.0022 - val_accuracy: 0.4831 - lr: 1.0000e-04\n",
      "Epoch 25/30\n",
      "782/782 [==============================] - 50s 65ms/step - loss: 2.0121 - accuracy: 0.4806 - val_loss: 2.0165 - val_accuracy: 0.4839 - lr: 1.0000e-04\n",
      "Epoch 26/30\n",
      "782/782 [==============================] - 48s 61ms/step - loss: 1.9131 - accuracy: 0.5003 - val_loss: 1.9968 - val_accuracy: 0.4958 - lr: 5.0000e-05\n",
      "Epoch 27/30\n",
      "782/782 [==============================] - 49s 63ms/step - loss: 1.8771 - accuracy: 0.5087 - val_loss: 1.9652 - val_accuracy: 0.5030 - lr: 5.0000e-05\n",
      "Epoch 28/30\n",
      "782/782 [==============================] - 49s 63ms/step - loss: 1.8568 - accuracy: 0.5146 - val_loss: 1.9536 - val_accuracy: 0.5039 - lr: 5.0000e-05\n",
      "Epoch 29/30\n",
      "782/782 [==============================] - 47s 60ms/step - loss: 1.8461 - accuracy: 0.5180 - val_loss: 1.9374 - val_accuracy: 0.5023 - lr: 5.0000e-05\n",
      "Epoch 30/30\n",
      "782/782 [==============================] - 47s 60ms/step - loss: 1.8198 - accuracy: 0.5247 - val_loss: 1.9302 - val_accuracy: 0.5062 - lr: 5.0000e-05\n"
     ]
    }
   ],
   "source": [
    "# Callbacks\n",
    "checkpoint_cb = ModelCheckpoint('checkpoints/mobilenetv2_finetuned_best.h5', save_best_only=True)\n",
    "early_stop_cb = EarlyStopping(patience=10, restore_best_weights=True)\n",
    "lr_cb = ReduceLROnPlateau(factor=0.5, patience=3, min_lr=1e-6)\n",
    "\n",
    "# Train more epochs\n",
    "history = model.fit(\n",
    "    train_gen,\n",
    "    validation_data=val_gen,\n",
    "    epochs=30,\n",
    "    callbacks=[checkpoint_cb, early_stop_cb, lr_cb],\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67266ff3",
   "metadata": {},
   "source": [
    "## Final evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ebe0b7a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "157/157 [==============================] - 5s 27ms/step - loss: 1.9302 - accuracy: 0.5062\n",
      "Final Validation Loss: 1.9302\n",
      "Final Validation Accuracy: 0.5062\n"
     ]
    }
   ],
   "source": [
    "model = load_model('checkpoints/mobilenetv2_finetuned_best.h5')\n",
    "loss, acc = model.evaluate(val_gen)\n",
    "print(f\"Final Validation Loss: {loss:.4f}\")\n",
    "print(f\"Final Validation Accuracy: {acc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d26db4b5-4016-40bb-bd4e-d030efa17c98",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
